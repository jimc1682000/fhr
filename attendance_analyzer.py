#!/usr/bin/env python3
"""
è€ƒå‹¤åˆ†æç³»çµ±
ç”¨æ–¼åˆ†æè€ƒå‹¤è¨˜éŒ„ä¸¦è¨ˆç®—é²åˆ°/åŠ ç­æ™‚æ•¸
"""

import re
import sys
import json
import os
import logging
import time
import ssl
import random
import socket
from collections import defaultdict
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
from urllib.parse import urlparse


logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


class AttendanceType(Enum):
    CHECKIN = "ä¸Šç­"
    CHECKOUT = "ä¸‹ç­"


class IssueType(Enum):
    LATE = "é²åˆ°"
    FORGET_PUNCH = "å¿˜åˆ·å¡"
    OVERTIME = "åŠ ç­"
    WFH = "WFHå‡"
    WEEKDAY_LEAVE = "è«‹å‡"


@dataclass
class AttendanceRecord:
    date: datetime
    scheduled_time: Optional[datetime]
    actual_time: Optional[datetime]
    type: AttendanceType
    card_number: str
    source: str
    status: str
    processed: str
    operation: str
    note: str


@dataclass
class WorkDay:
    date: datetime
    checkin_record: Optional[AttendanceRecord]
    checkout_record: Optional[AttendanceRecord]
    is_friday: bool
    is_holiday: bool = False


@dataclass
class Issue:
    date: datetime
    type: IssueType
    duration_minutes: int
    description: str
    time_range: str = ""
    calculation: str = ""
    is_new: bool = True  # æ¨™ç¤ºæ˜¯å¦ç‚ºæœ¬æ¬¡æ–°ç™¼ç¾çš„å•é¡Œ


    # AttendanceStateManager å·²æŠ½é›¢è‡³ lib.state


class AttendanceAnalyzer:
    """è€ƒå‹¤åˆ†æå™¨"""
    
    # å…¬å¸è¦å‰‡å¸¸æ•¸ï¼ˆå¯ç”±è¨­å®šæª”è¦†è“‹ï¼‰
    EARLIEST_CHECKIN = "08:30"
    LATEST_CHECKIN = "10:30"
    LUNCH_START = "12:30"
    LUNCH_END = "13:30"
    WORK_HOURS = 8
    LUNCH_HOURS = 1
    MIN_OVERTIME_MINUTES = 60
    OVERTIME_INCREMENT_MINUTES = 60  # æ”¹ç‚ºæ¯å°æ™‚ä¸€å€‹å€é–“
    FORGET_PUNCH_ALLOWANCE_PER_MONTH = 2  # æ¯æœˆå¿˜åˆ·å¡æ¬¡æ•¸
    FORGET_PUNCH_MAX_MINUTES = 60  # å¿˜åˆ·å¡æœ€å¤šå¯ç”¨æ–¼60åˆ†é˜å…§çš„é²åˆ°

    def __init__(self, config_path: str = "config.json"):
        self._load_config(config_path)
        self.records: List[AttendanceRecord] = []
        self.workdays: List[WorkDay] = []
        self.issues: List[Issue] = []
        self.holidays: set = set()  # å­˜æ”¾åœ‹å®šå‡æ—¥æ—¥æœŸ
        self.forget_punch_usage: Dict[str, int] = defaultdict(int)  # è¿½è¹¤æ¯æœˆå¿˜åˆ·å¡ä½¿ç”¨æ¬¡æ•¸ {å¹´æœˆ: æ¬¡æ•¸}
        self.loaded_holiday_years: set = set()  # è¿½è¹¤å·²è¼‰å…¥å‡æ—¥çš„å¹´ä»½
        self.state_manager: Optional[AttendanceStateManager] = None
        self.current_user: Optional[str] = None
        self.incremental_mode: bool = True

    def _load_config(self, config_path: str) -> None:
        """è¼‰å…¥è¨­å®šæª”ä»¥è¦†è“‹é è¨­å…¬å¸è¦å‰‡"""
        if not os.path.exists(config_path):
            logger.info("æ‰¾ä¸åˆ°è¨­å®šæª” %sï¼Œä½¿ç”¨é è¨­å€¼", config_path)
            return
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for key, value in data.items():
                if hasattr(self, key):
                    setattr(self, key, value)
        except (OSError, json.JSONDecodeError) as e:
            logger.warning("ç„¡æ³•è®€å–è¨­å®šæª” %s: %s", config_path, e)
    
    
    def _identify_complete_work_days(self) -> List[datetime]:
        """è­˜åˆ¥å®Œæ•´çš„å·¥ä½œæ—¥ï¼ˆæœ‰ä¸Šç­å’Œä¸‹ç­è¨˜éŒ„çš„æ—¥æœŸï¼‰
        Returns:
            å®Œæ•´å·¥ä½œæ—¥çš„æ—¥æœŸæ¸…å–®
        """
        complete_days = []
        daily_records = defaultdict(lambda: {'checkin': False, 'checkout': False})

        # æŒ‰æ—¥æœŸåˆ†çµ„è¨˜éŒ„
        for record in self.records:
            if not record.date:
                continue

            if record.type == AttendanceType.CHECKIN:
                daily_records[record.date]['checkin'] = True
            else:
                daily_records[record.date]['checkout'] = True
        
        # æ‰¾å‡ºæœ‰ä¸Šç­å’Œä¸‹ç­è¨˜éŒ„çš„å®Œæ•´å·¥ä½œæ—¥
        for date, records in daily_records.items():
            if records['checkin'] and records['checkout']:
                complete_days.append(datetime.combine(date, datetime.min.time()))
        
        return sorted(complete_days)
    
    def _get_unprocessed_dates(self, user_name: str, complete_days: List[datetime]) -> List[datetime]:
        """å–å¾—éœ€è¦è™•ç†çš„æ–°æ—¥æœŸï¼ˆæ’é™¤å·²è™•ç†çš„é‡ç–Šæ—¥æœŸï¼‰
        Args:
            user_name: ä½¿ç”¨è€…å§“å
            complete_days: å®Œæ•´å·¥ä½œæ—¥æ¸…å–®
        Returns:
            éœ€è¦è™•ç†çš„æ—¥æœŸæ¸…å–®
        """
        if not self.state_manager or not self.incremental_mode:
            return complete_days
        
        processed_ranges = self.state_manager.get_user_processed_ranges(user_name)
        unprocessed_dates = []
        
        for day in complete_days:
            day_str = day.strftime("%Y-%m-%d")
            is_processed = False
            
            # æª¢æŸ¥é€™å€‹æ—¥æœŸæ˜¯å¦å·²åœ¨ä¹‹å‰è™•ç†éçš„ç¯„åœå…§
            for range_info in processed_ranges:
                if range_info["start_date"] <= day_str <= range_info["end_date"]:
                    is_processed = True
                    break
            
            if not is_processed:
                unprocessed_dates.append(day)
        
        return unprocessed_dates
    
    def _load_previous_forget_punch_usage(self, user_name: str) -> None:
        """è¼‰å…¥ä¹‹å‰çš„å¿˜åˆ·å¡ä½¿ç”¨çµ±è¨ˆ"""
        if not self.state_manager or not self.incremental_mode:
            return
        
        # æ¸…ç©ºç¾æœ‰çµ±è¨ˆ
        self.forget_punch_usage = defaultdict(int)
        
        # å¾ç‹€æ…‹ç®¡ç†å™¨è¼‰å…¥
        user_data = self.state_manager.state_data.get("users", {}).get(user_name, {})
        previous_usage = user_data.get("forget_punch_usage", {})
        
        # è¤‡è£½åˆ°æœ¬åœ°çµ±è¨ˆ
        self.forget_punch_usage.update(previous_usage)
    
    def _get_years_from_records(self) -> set:
        """å¾å‡ºå‹¤è¨˜éŒ„ä¸­æå–å¹´ä»½"""
        years = set()
        for record in self.records:
            if record.date:
                years.add(record.date.year)
        return years
    
    def _load_taiwan_holidays(self, years: set = None) -> None:
        """è¼‰å…¥å°ç£åœ‹å®šå‡æ—¥è³‡æ–™
        Args:
            years: éœ€è¦è¼‰å…¥çš„å¹´ä»½é›†åˆï¼ŒNoneè¡¨ç¤ºåªè¼‰å…¥ç•¶å¹´(2025)
        """
        if years is None:
            years = {2025}  # é è¨­è¼‰å…¥ç•¶å¹´
        
        for year in years:
            if year not in self.loaded_holiday_years:
                from lib.holidays import HolidayService
                logger.info("è³‡è¨Š: å‹•æ…‹è¼‰å…¥ %d å¹´åœ‹å®šå‡æ—¥...", year)
                service = HolidayService()
                self.holidays |= service.load_year(year)
                self.loaded_holiday_years.add(year)
    
    def _load_hardcoded_2025_holidays(self) -> None:
        """è¼‰å…¥ç¡¬ç·¨ç¢¼çš„2025å¹´åœ‹å®šå‡æ—¥ï¼ˆå§”æ´¾ lib.holidaysï¼‰"""
        from lib.holidays import Hardcoded2025Provider
        self.holidays |= Hardcoded2025Provider().load(2025)
    
    def _load_dynamic_holidays(self, year: int) -> None:
        """å‹•æ…‹è¼‰å…¥æŒ‡å®šå¹´ä»½çš„åœ‹å®šå‡æ—¥
        Args:
            year: è¦è¼‰å…¥çš„å¹´ä»½
        """
        logger.info("è³‡è¨Š: å‹•æ…‹è¼‰å…¥ %d å¹´åœ‹å®šå‡æ—¥...", year)
        success = self._try_load_from_gov_api(year)
        if not success:
            self._load_basic_holidays(year)
            logger.warning("ç„¡æ³•å–å¾— %d å¹´å®Œæ•´å‡æ—¥è³‡æ–™ï¼Œåƒ…è¼‰å…¥åŸºæœ¬å›ºå®šå‡æ—¥", year)
    
    def _try_load_from_gov_api(self, year: int) -> bool:
        # å‘å¾Œç›¸å®¹ï¼šä¿ç•™æœ¬æ¨¡çµ„å…§çš„ scheme æª¢æŸ¥ï¼ˆä¾›å–®å…ƒæ¸¬è©¦ patchï¼‰
        url = "https://data.gov.tw/api/v1/rest/datastore_search?resource_id=W2&filters={\"date\":\"%s\"}" % year
        parsed = urlparse(url)
        if parsed.scheme not in {"http", "https"}:
            logger.warning("ä¸æ”¯æ´çš„ URL scheme: %s", parsed.scheme)
            return False
        from lib.holidays import TaiwanGovOpenDataProvider
        out = TaiwanGovOpenDataProvider().load(year)
        if out:
            self.holidays |= out
            return True
        return False

    def _load_basic_holidays(self, year: int) -> None:
        from lib.holidays import BasicFixedProvider
        self.holidays |= BasicFixedProvider().load(year)
    
    def parse_attendance_file(self, filepath: str, incremental: bool = True) -> None:
        """è§£æè€ƒå‹¤è³‡æ–™æª”æ¡ˆä¸¦åˆå§‹åŒ–å¢é‡è™•ç†
        Args:
            filepath: æª”æ¡ˆè·¯å¾‘
            incremental: æ˜¯å¦å•Ÿç”¨å¢é‡åˆ†æ
        """
        self.incremental_mode = incremental
        
        # åˆå§‹åŒ–ç‹€æ…‹ç®¡ç†å™¨
        if self.incremental_mode:
            from lib.state import AttendanceStateManager
            self.state_manager = AttendanceStateManager()
            
            # è§£ææª”åå–å¾—ä½¿ç”¨è€…è³‡è¨Š
            from lib.filename import parse_range_and_user
            user_name, start_date, end_date = parse_range_and_user(filepath)
            if user_name:
                self.current_user = user_name
                logger.info("ğŸ“‹ è­˜åˆ¥ä½¿ç”¨è€…: %s", user_name)
                logger.info("ğŸ“… æª”æ¡ˆæ¶µè“‹æœŸé–“: %s è‡³ %s", start_date, end_date)
                
                # æª¢æŸ¥é‡ç–Šæ—¥æœŸ
                if start_date and end_date:
                    overlaps = self.state_manager.detect_date_overlap(user_name, start_date, end_date)
                    if overlaps:
                        logger.warning("âš ï¸  ç™¼ç¾é‡ç–Šæ—¥æœŸç¯„åœ: %s", overlaps)
                        logger.warning("å°‡ä»¥èˆŠè³‡æ–™ç‚ºä¸»ï¼Œåƒ…è™•ç†æ–°æ—¥æœŸ")
                
                # è¼‰å…¥ä¹‹å‰çš„å¿˜åˆ·å¡ä½¿ç”¨çµ±è¨ˆ
                self._load_previous_forget_punch_usage(user_name)
            else:
                logger.warning("âš ï¸  ç„¡æ³•å¾æª”åè­˜åˆ¥ä½¿ç”¨è€…ï¼Œå°‡ä½¿ç”¨å®Œæ•´åˆ†ææ¨¡å¼")
                self.incremental_mode = False
        
        # è§£ææª”æ¡ˆå…§å®¹
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        for line_num, line in enumerate(lines, 1):
            if line_num == 1:  # è·³éè¡¨é ­
                continue
                
            line = line.strip()
            if not line:
                continue
                
            try:
                record = self._parse_attendance_line(line)
                if record:
                    self.records.append(record)
            except (ValueError, IndexError) as e:
                logger.warning("ç¬¬%dè¡Œè§£æå¤±æ•—: %s", line_num, e)
    
    def _parse_attendance_line(self, line: str) -> Optional[AttendanceRecord]:
        """è§£æå–®è¡Œè€ƒå‹¤è¨˜éŒ„"""
        # ç§»é™¤è¡Œè™Ÿå‰ç¶´
        line = re.sub(r'^\s*\d+â†’', '', line)
        
        # åˆ†å‰²æ¬„ä½
        fields = line.split('\t')
        if len(fields) < 3:
            return None
        
        # è£œé½Šæ¬„ä½åˆ°9å€‹
        while len(fields) < 9:
            fields.append('')
        
        scheduled_str, actual_str, type_str = fields[0], fields[1], fields[2]
        card_num, source, status = fields[3], fields[4], fields[5]
        processed, operation, note = fields[6], fields[7], fields[8]
        
        # è§£ææ—¥æœŸæ™‚é–“
        scheduled_time = self._parse_datetime(scheduled_str) if scheduled_str else None
        actual_time = self._parse_datetime(actual_str) if actual_str else None
        
        # è·³éç„¡æ•ˆè¨˜éŒ„
        if not scheduled_time or type_str not in ["ä¸Šç­", "ä¸‹ç­"]:
            return None
        
        # è§£æè€ƒå‹¤é¡å‹
        attendance_type = AttendanceType.CHECKIN if type_str == "ä¸Šç­" else AttendanceType.CHECKOUT
        
        return AttendanceRecord(
            date=scheduled_time.date() if scheduled_time else None,
            scheduled_time=scheduled_time,
            actual_time=actual_time,
            type=attendance_type,
            card_number=card_num,
            source=source,
            status=status,
            processed=processed,
            operation=operation,
            note=note
        )
    
    def _parse_datetime(self, datetime_str: str) -> Optional[datetime]:
        """è§£ææ—¥æœŸæ™‚é–“å­—ä¸²"""
        try:
            return datetime.strptime(datetime_str, "%Y/%m/%d %H:%M")
        except ValueError:
            return None
    
    def group_records_by_day(self) -> None:
        """å°‡è¨˜éŒ„æŒ‰æ—¥æœŸåˆ†çµ„"""
        # åœ¨åˆ†çµ„å‰ï¼Œå…ˆè¼‰å…¥å‡ºå‹¤è³‡æ–™ä¸­æ¶‰åŠçš„å¹´ä»½å‡æ—¥
        years_in_data = self._get_years_from_records()
        if years_in_data:
            self._load_taiwan_holidays(years_in_data)
        
        daily_records = defaultdict(lambda: {'checkin': None, 'checkout': None})

        for record in self.records:
            if not record.date:
                continue

            if record.type == AttendanceType.CHECKIN:
                daily_records[record.date]['checkin'] = record
            else:
                daily_records[record.date]['checkout'] = record
        
        for date, records in daily_records.items():
            workday = WorkDay(
                date=datetime.combine(date, datetime.min.time()),
                checkin_record=records['checkin'],
                checkout_record=records['checkout'],
                is_friday=(date.weekday() == 4),  # é€±äº”æ˜¯4
                is_holiday=(date in self.holidays)  # æª¢æŸ¥æ˜¯å¦ç‚ºåœ‹å®šå‡æ—¥
            )
            self.workdays.append(workday)
        
        self.workdays.sort(key=lambda x: x.date)
    
    def analyze_attendance(self) -> None:
        """åˆ†æè€ƒå‹¤è¨˜éŒ„ï¼ˆæ”¯æ´å¢é‡åˆ†æï¼‰"""
        self.issues = []
        
        # å¢é‡åˆ†ææ¨¡å¼ï¼šåªåˆ†ææ–°çš„å®Œæ•´å·¥ä½œæ—¥
        if self.incremental_mode and self.current_user:
            complete_days = self._identify_complete_work_days()
            unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
            
            if unprocessed_dates:
                logger.info("ğŸ”„ å¢é‡åˆ†æ: ç™¼ç¾ %d å€‹æ–°çš„å®Œæ•´å·¥ä½œæ—¥éœ€è¦è™•ç†", len(unprocessed_dates))
                logger.info("ğŸ“Š è·³éå·²è™•ç†çš„å·¥ä½œæ—¥: %d å€‹", len(complete_days) - len(unprocessed_dates))
                
                # åªåˆ†ææœªè™•ç†çš„å·¥ä½œæ—¥
                unprocessed_date_set = {d.date() for d in unprocessed_dates}
                workdays_to_analyze = [wd for wd in self.workdays if wd.date.date() in unprocessed_date_set]
            else:
                logger.info("âœ… å¢é‡åˆ†æ: æ²’æœ‰æ–°çš„å·¥ä½œæ—¥éœ€è¦è™•ç†")
                workdays_to_analyze = []
        else:
            # å®Œæ•´åˆ†ææ¨¡å¼ï¼šåˆ†ææ‰€æœ‰å·¥ä½œæ—¥
            workdays_to_analyze = self.workdays
        
        from lib.policy import Rules, is_full_day_absent, calculate_late_minutes, calculate_overtime_minutes
        rules = Rules(
            earliest_checkin=self.EARLIEST_CHECKIN,
            latest_checkin=self.LATEST_CHECKIN,
            lunch_start=self.LUNCH_START,
            lunch_end=self.LUNCH_END,
            work_hours=self.WORK_HOURS,
            lunch_hours=self.LUNCH_HOURS,
            min_overtime_minutes=self.MIN_OVERTIME_MINUTES,
            overtime_increment_minutes=self.OVERTIME_INCREMENT_MINUTES,
            forget_punch_allowance_per_month=self.FORGET_PUNCH_ALLOWANCE_PER_MONTH,
            forget_punch_max_minutes=self.FORGET_PUNCH_MAX_MINUTES,
        )

        for workday in workdays_to_analyze:
            # æª¢æŸ¥æ˜¯å¦æ•´å¤©æ²’æœ‰æ‰“å¡è¨˜éŒ„ï¼ˆæ› è·ï¼‰
            if is_full_day_absent(workday):
                if workday.is_friday and not workday.is_holiday:
                    # é€±äº”ä¸”éåœ‹å®šå‡æ—¥å»ºè­°WFHå‡
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.WFH,
                        duration_minutes=9 * 60,  # 9å°æ™‚
                        description="å»ºè­°ç”³è«‹æ•´å¤©WFHå‡ ğŸ ğŸ’»"
                    ))
                elif not workday.is_holiday:
                    # éåœ‹å®šå‡æ—¥çš„é€±ä¸€åˆ°é€±å››å»ºè­°è«‹å‡
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.WEEKDAY_LEAVE,
                        duration_minutes=8 * 60,  # 8å°æ™‚
                        description="æ•´å¤©æ²’é€²å…¬å¸ï¼Œå»ºè­°è«‹å‡ ğŸ“ğŸ "
                    ))
                # å¦‚æœæ˜¯åœ‹å®šå‡æ—¥ï¼Œå‰‡ä¸éœ€è¦ä»»ä½•ç”³è«‹å»ºè­°
                continue
            
            if workday.is_friday:
                # é€±äº”å·²è™•ç†ï¼Œè·³éåˆ†æ
                continue
            
            # åˆ†æé²åˆ°
            late_minutes, late_time_range, late_calculation = calculate_late_minutes(workday, rules)
            if late_minutes > 0:
                # æª¢æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨å¿˜åˆ·å¡
                month_key = workday.date.strftime('%Y-%m')
                can_use_forget_punch = (
                    late_minutes <= self.FORGET_PUNCH_MAX_MINUTES and
                    self.forget_punch_usage[month_key] < self.FORGET_PUNCH_ALLOWANCE_PER_MONTH
                )
                
                if can_use_forget_punch:
                    # ä½¿ç”¨å¿˜åˆ·å¡
                    self.forget_punch_usage[month_key] += 1
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.FORGET_PUNCH,
                        duration_minutes=0,  # å¿˜åˆ·å¡ä¸éœ€è¦è«‹å‡
                        description=f"é²åˆ°{late_minutes}åˆ†é˜ï¼Œå»ºè­°ä½¿ç”¨å¿˜åˆ·å¡ ğŸ”„âœ…",
                        time_range=late_time_range,
                        calculation=f"{late_calculation} (ä½¿ç”¨å¿˜åˆ·å¡ï¼Œæœ¬æœˆå‰©é¤˜: {self.FORGET_PUNCH_ALLOWANCE_PER_MONTH - self.forget_punch_usage[month_key]}æ¬¡)"
                    ))
                else:
                    # éœ€è¦è«‹é²åˆ°å‡
                    reason = "è¶…é1å°æ™‚" if late_minutes > self.FORGET_PUNCH_MAX_MINUTES else f"æœ¬æœˆå¿˜åˆ·å¡é¡åº¦å·²ç”¨å®Œ"
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.LATE,
                        duration_minutes=late_minutes,
                        description=f"é²åˆ°{late_minutes}åˆ†é˜ â±ï¸ ({reason})",
                        time_range=late_time_range,
                        calculation=late_calculation
                    ))
            
            # åˆ†æåŠ ç­
            actual_overtime, applicable_overtime, overtime_time_range, overtime_calculation = calculate_overtime_minutes(workday, rules)
            if applicable_overtime >= self.MIN_OVERTIME_MINUTES:
                self.issues.append(Issue(
                    date=workday.date,
                    type=IssueType.OVERTIME,
                    duration_minutes=applicable_overtime,
                    description=f"åŠ ç­{applicable_overtime // 60}å°æ™‚{applicable_overtime % 60}åˆ†é˜ ğŸ’¼",
                    time_range=overtime_time_range,
                    calculation=overtime_calculation
                ))
        
        # å¢é‡åˆ†ææ¨¡å¼ï¼šæ›´æ–°ç‹€æ…‹
        if self.incremental_mode and self.current_user and workdays_to_analyze:
            self._update_processing_state()
    
    def _update_processing_state(self) -> None:
        """æ›´æ–°è™•ç†ç‹€æ…‹åˆ°ç‹€æ…‹æª”æ¡ˆ"""
        if not self.state_manager or not self.current_user:
            return
        
        # è¨ˆç®—è™•ç†ç¯„åœ
        complete_days = self._identify_complete_work_days()
        if not complete_days:
            return
        
        start_date = min(complete_days).strftime("%Y-%m-%d")
        end_date = max(complete_days).strftime("%Y-%m-%d")
        
        # æ§‹å»ºç¯„åœè³‡è¨Š
        range_info = {
            "start_date": start_date,
            "end_date": end_date,
            "source_file": os.path.basename(sys.argv[1]) if len(sys.argv) > 1 else "unknown",
            "last_analysis_time": datetime.now().isoformat()
        }
        
        # æ›´æ–°ç‹€æ…‹
        self.state_manager.update_user_state(
            self.current_user,
            range_info,
            self.forget_punch_usage
        )
        
        # å„²å­˜ç‹€æ…‹æª”æ¡ˆ
        self.state_manager.save_state()
        logger.info("ğŸ’¾ å·²æ›´æ–°è™•ç†ç‹€æ…‹: %s è‡³ %s", start_date, end_date)
    
    def _calculate_late_minutes(self, workday: WorkDay) -> tuple:
        """è¨ˆç®—é²åˆ°åˆ†é˜æ•¸ï¼Œè¿”å› (åˆ†é˜æ•¸, æ™‚æ®µ, è¨ˆç®—å¼)"""
        if not workday.checkin_record or not workday.checkin_record.actual_time:
            return 0, "", ""
        
        latest_checkin = datetime.strptime(f"{workday.date.strftime('%Y/%m/%d')} {self.LATEST_CHECKIN}", "%Y/%m/%d %H:%M")
        actual_checkin = workday.checkin_record.actual_time
        
        if actual_checkin > latest_checkin:
            delta = actual_checkin - latest_checkin
            late_minutes = int(delta.total_seconds() // 60)
            
            # å¦‚æœé²åˆ°è¶…é2å°æ™‚ï¼Œéœ€è¦æ‰£é™¤åˆä¼‘æ™‚é–“
            if late_minutes > 120:  # è¶…é2å°æ™‚
                lunch_start = datetime.strptime(f"{workday.date.strftime('%Y/%m/%d')} {self.LUNCH_START}", "%Y/%m/%d %H:%M")
                lunch_end = datetime.strptime(f"{workday.date.strftime('%Y/%m/%d')} {self.LUNCH_END}", "%Y/%m/%d %H:%M")
                
                # å¦‚æœä¸Šç­æ™‚é–“è·¨è¶Šåˆä¼‘æ™‚æ®µï¼Œæ‰£é™¤åˆä¼‘æ™‚é–“
                if actual_checkin > lunch_start:
                    late_minutes -= 60  # æ‰£é™¤1å°æ™‚åˆä¼‘
                    calculation = f"å¯¦éš›ä¸Šç­: {actual_checkin.strftime('%H:%M')}, æœ€æ™šä¸Šç­: {self.LATEST_CHECKIN}, é²åˆ°: {int(delta.total_seconds() // 60)}åˆ†é˜ - 60åˆ†é˜åˆä¼‘ = {late_minutes}åˆ†é˜"
                else:
                    calculation = f"å¯¦éš›ä¸Šç­: {actual_checkin.strftime('%H:%M')}, æœ€æ™šä¸Šç­: {self.LATEST_CHECKIN}, é²åˆ°: {late_minutes}åˆ†é˜"
            else:
                calculation = f"å¯¦éš›ä¸Šç­: {actual_checkin.strftime('%H:%M')}, æœ€æ™šä¸Šç­: {self.LATEST_CHECKIN}, é²åˆ°: {late_minutes}åˆ†é˜"
            
            time_range = f"{self.LATEST_CHECKIN}~{actual_checkin.strftime('%H:%M')}"
            return late_minutes, time_range, calculation
        
        return 0, "", ""
    
    def _calculate_overtime_minutes(self, workday: WorkDay) -> tuple:
        """è¨ˆç®—åŠ ç­åˆ†é˜æ•¸ï¼Œè¿”å› (å¯¦éš›åˆ†é˜æ•¸, å¯ç”³è«‹åˆ†é˜æ•¸, æ™‚æ®µ, è¨ˆç®—å¼)"""
        if (not workday.checkin_record or not workday.checkin_record.actual_time or
            not workday.checkout_record or not workday.checkout_record.actual_time):
            return 0, 0, "", ""
        
        checkin_time = workday.checkin_record.actual_time
        checkout_time = workday.checkout_record.actual_time
        
        # è¨ˆç®—æ‡‰ä¸‹ç­æ™‚é–“ = ä¸Šç­æ™‚é–“ + 8å°æ™‚å·¥ä½œ + 1å°æ™‚åˆä¼‘
        expected_checkout = checkin_time + timedelta(hours=self.WORK_HOURS + self.LUNCH_HOURS)
        
        if checkout_time > expected_checkout:
            delta = checkout_time - expected_checkout
            actual_overtime_minutes = int(delta.total_seconds() // 60)
            
            # æŒ‰åŠå°æ™‚é–“éš”è¨ˆç®—å¯ç”³è«‹æ™‚æ•¸
            if actual_overtime_minutes >= self.MIN_OVERTIME_MINUTES:
                # è¨ˆç®—å¯ç”³è«‹çš„åŠå°æ™‚é–“éš”æ•¸
                intervals = (actual_overtime_minutes - self.MIN_OVERTIME_MINUTES) // self.OVERTIME_INCREMENT_MINUTES
                applicable_minutes = self.MIN_OVERTIME_MINUTES + (intervals * self.OVERTIME_INCREMENT_MINUTES)
                
                time_range = f"{expected_checkout.strftime('%H:%M')}~{checkout_time.strftime('%H:%M')}"
                calculation = f"é æœŸä¸‹ç­: {expected_checkout.strftime('%H:%M')}, å¯¦éš›ä¸‹ç­: {checkout_time.strftime('%H:%M')}, å¯¦éš›åŠ ç­: {actual_overtime_minutes}åˆ†é˜, å¯ç”³è«‹: {applicable_minutes}åˆ†é˜"
                
                return actual_overtime_minutes, applicable_minutes, time_range, calculation
        
        return 0, 0, "", ""
    
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå ±å‘Šï¼ˆæ”¯æ´å¢é‡åˆ†æè³‡è¨Šé¡¯ç¤ºï¼‰"""
        report = []
        report.append("# ğŸ¯ è€ƒå‹¤åˆ†æå ±å‘Š âœ¨\n")
        
        # é¡¯ç¤ºå¢é‡åˆ†æè³‡è¨Š
        if self.incremental_mode and self.current_user:
            complete_days = self._identify_complete_work_days()
            unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
            
            report.append("## ğŸ“ˆ å¢é‡åˆ†æè³‡è¨Šï¼š\n")
            report.append(f"- ğŸ‘¤ ä½¿ç”¨è€…ï¼š{self.current_user}")
            report.append(f"- ğŸ“Š ç¸½å®Œæ•´å·¥ä½œæ—¥ï¼š{len(complete_days)} å¤©")
            report.append(f"- ğŸ”„ æ–°è™•ç†å·¥ä½œæ—¥ï¼š{len(unprocessed_dates)} å¤©")
            report.append(f"- â­ï¸  è·³éå·²è™•ç†ï¼š{len(complete_days) - len(unprocessed_dates)} å¤©")
            
            if unprocessed_dates:
                new_dates_str = ", ".join([d.strftime('%Y/%m/%d') for d in unprocessed_dates[:5]])
                if len(unprocessed_dates) > 5:
                    new_dates_str += f" ç­‰ {len(unprocessed_dates)} å¤©"
                report.append(f"- ğŸ“… æ–°è™•ç†æ—¥æœŸï¼š{new_dates_str}")
            report.append("")
        
        # å¿˜åˆ·å¡å»ºè­°
        forget_punch_issues = [issue for issue in self.issues if issue.type == IssueType.FORGET_PUNCH]
        if forget_punch_issues:
            report.append("## ğŸ”„ å»ºè­°ä½¿ç”¨å¿˜åˆ·å¡çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(forget_punch_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ”„ {issue.description}")
                report.append(f"   â° æ™‚æ®µ: {issue.time_range}")
                report.append(f"   ğŸ§® è¨ˆç®—: {issue.calculation}")
                report.append("")
        
        # é²åˆ°çµ±è¨ˆ
        late_issues = [issue for issue in self.issues if issue.type == IssueType.LATE]
        if late_issues:
            report.append("## ğŸ˜° éœ€è¦è«‹é²åˆ°çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(late_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ˜… {issue.description}")
                report.append(f"   â° æ™‚æ®µ: {issue.time_range}")
                report.append(f"   ğŸ§® è¨ˆç®—: {issue.calculation}")
                report.append("")
        
        # åŠ ç­çµ±è¨ˆ
        overtime_issues = [issue for issue in self.issues if issue.type == IssueType.OVERTIME]
        if overtime_issues:
            report.append("## ğŸ’ª éœ€è¦è«‹åŠ ç­çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(overtime_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ”¥ {issue.description}")
                report.append(f"   â° æ™‚æ®µ: {issue.time_range}")
                report.append(f"   ğŸ§® è¨ˆç®—: {issue.calculation}")
                report.append("")
        
        # é€±ä¸€åˆ°é€±å››è«‹å‡å»ºè­°
        weekday_leave_issues = [issue for issue in self.issues if issue.type == IssueType.WEEKDAY_LEAVE]
        if weekday_leave_issues:
            report.append("## ğŸ“ éœ€è¦è«‹å‡çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(weekday_leave_issues, 1):
                weekday_name = ['é€±ä¸€', 'é€±äºŒ', 'é€±ä¸‰', 'é€±å››', 'é€±äº”', 'é€±å…­', 'é€±æ—¥'][issue.date.weekday()]
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')} ({weekday_name})** - ğŸ“ {issue.description}")
            report.append("")
        
        # WFHå»ºè­°
        wfh_issues = [issue for issue in self.issues if issue.type == IssueType.WFH]
        if wfh_issues:
            report.append("## ğŸ  å»ºè­°ç”³è«‹WFHå‡çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(wfh_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ˜Š {issue.description}")
            report.append("")
        
        # çµ±è¨ˆæ‘˜è¦
        report.append("## ğŸ“Š çµ±è¨ˆæ‘˜è¦ï¼š\n")
        report.append(f"- ğŸ”„ å»ºè­°å¿˜åˆ·å¡å¤©æ•¸ï¼š{len(forget_punch_issues)} å¤©")
        report.append(f"- ğŸ˜° éœ€è¦è«‹é²åˆ°å¤©æ•¸ï¼š{len(late_issues)} å¤©")
        report.append(f"- ğŸ’ª åŠ ç­å¤©æ•¸ï¼š{len(overtime_issues)} å¤©")
        report.append(f"- ğŸ“ éœ€è¦è«‹å‡å¤©æ•¸ï¼š{len(weekday_leave_issues)} å¤©")
        report.append(f"- ğŸ  å»ºè­°WFHå¤©æ•¸ï¼š{len(wfh_issues)} å¤©")
        
        return "\n".join(report)
    
    def export_csv(self, filepath: str) -> None:
        """åŒ¯å‡ºCSVæ ¼å¼å ±å‘Šï¼ˆå§”æ´¾è‡³ lib.csv_exporterï¼‰"""
        from lib import csv_exporter

        status_tuple = None
        if self.incremental_mode and not self.issues and self.current_user:
            complete_days = self._identify_complete_work_days()
            if complete_days:
                last_date = max(complete_days).strftime('%Y/%m/%d')
                unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
                # è®€å–ä¸Šæ¬¡åˆ†ææ™‚é–“
                last_analysis_time = ""
                if self.state_manager and self.current_user:
                    user_data = self.state_manager.state_data.get("users", {}).get(self.current_user, {})
                    ranges = user_data.get("processed_date_ranges", [])
                    if ranges:
                        last_analysis_time = max((r.get("last_analysis_time", "") for r in ranges), default="")
                if not unprocessed_dates:
                    status_tuple = (last_date, len(complete_days), last_analysis_time)

        csv_exporter.save_csv(filepath, self.issues, self.incremental_mode, status_tuple)
    
    def export_excel(self, filepath: str) -> None:
        """åŒ¯å‡ºExcelæ ¼å¼å ±å‘Š"""
        try:
            from lib import excel_exporter
        except ImportError:
            logger.warning("âš ï¸  è­¦å‘Š: æœªå®‰è£ openpyxlï¼Œå›é€€ä½¿ç”¨CSVæ ¼å¼")
            logger.info("ğŸ’¡ å®‰è£æŒ‡ä»¤: pip install openpyxl")
            csv_filepath = filepath.replace('.xlsx', '.csv')
            self.export_csv(csv_filepath)
            logger.info("âœ… CSVå ±å‘Šå·²åŒ¯å‡º: %s", csv_filepath)
            return

        wb, ws, header_font, header_fill, border, center_alignment = (
            excel_exporter.init_workbook()
        )

        headers = ['æ—¥æœŸ', 'é¡å‹', 'æ™‚é•·(åˆ†é˜)', 'èªªæ˜', 'æ™‚æ®µ', 'è¨ˆç®—å¼']
        if self.incremental_mode:
            headers.append('ç‹€æ…‹')
        excel_exporter.write_headers(
            ws, headers, header_font, header_fill, border, center_alignment
        )

        data_start_row = 2
        if self.incremental_mode and not self.issues and self.current_user:
            complete_days = self._identify_complete_work_days()
            if complete_days:
                last_date = max(complete_days).strftime('%Y/%m/%d')
                unprocessed_dates = self._get_unprocessed_dates(
                    self.current_user, complete_days
                )
                # è®€å–ä¸Šæ¬¡åˆ†ææ™‚é–“
                last_analysis_time = ""
                if self.state_manager and self.current_user:
                    user_data = self.state_manager.state_data.get("users", {}).get(self.current_user, {})
                    ranges = user_data.get("processed_date_ranges", [])
                    if ranges:
                        last_analysis_time = max((r.get("last_analysis_time", "") for r in ranges), default="")
                if not unprocessed_dates:
                    data_start_row = excel_exporter.write_status_row(
                        ws, last_date, len(complete_days), last_analysis_time, border, center_alignment
                    )

        excel_exporter.write_issue_rows(
            ws,
            self.issues,
            data_start_row,
            self.incremental_mode,
            border,
            center_alignment,
        )

        excel_exporter.set_column_widths(ws, self.incremental_mode)
        excel_exporter.save_workbook(wb, filepath)

    def _backup_existing_file(self, filepath: str) -> None:
        """å‚™ä»½ç¾æœ‰æª”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œä½¿ç”¨æ™‚é–“æˆ³è¨˜ä½œç‚ºå¾Œç¶´
        Args:
            filepath: è¦æª¢æŸ¥ä¸¦å‚™ä»½çš„æª”æ¡ˆè·¯å¾‘
        """
        import os
        from datetime import datetime
        
        if os.path.exists(filepath):
            # ç”¢ç”Ÿæ™‚é–“æˆ³è¨˜å¾Œç¶´ (æ ¼å¼: YYYYMMDD_HHMMSS)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # åˆ†é›¢æª”åå’Œå‰¯æª”å
            base_name, ext = os.path.splitext(filepath)
            backup_filepath = f"{base_name}_{timestamp}{ext}"
            
            # å‚™ä»½æª”æ¡ˆ
            os.rename(filepath, backup_filepath)
            logger.info("ğŸ“¦ å‚™ä»½ç¾æœ‰æª”æ¡ˆ: %s", os.path.basename(backup_filepath))
    
    def export_report(self, filepath: str, format_type: str = 'excel') -> None:
        """çµ±ä¸€åŒ¯å‡ºä»‹é¢
        Args:
            filepath: æª”æ¡ˆè·¯å¾‘
            format_type: 'excel' æˆ– 'csv'
        """
        # åŒ¯å‡ºå‰å…ˆå‚™ä»½ç¾æœ‰æª”æ¡ˆï¼ˆç§»è‡³ lib.backupï¼‰
        from lib.backup import backup_with_timestamp
        backup_path = backup_with_timestamp(filepath)
        if backup_path:
            print(f"ğŸ“¦ å‚™ä»½ç¾æœ‰æª”æ¡ˆ: {os.path.basename(backup_path)}")
        
        if format_type.lower() == 'csv':
            self.export_csv(filepath)
        else:
            self.export_excel(filepath)


def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='è€ƒå‹¤åˆ†æç³»çµ± - æ”¯æ´å¢é‡åˆ†æé¿å…é‡è¤‡è™•ç†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:
  # é è¨­å¢é‡åˆ†æï¼ˆæ¨è–¦ï¼‰
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt
  
  # å¼·åˆ¶å®Œæ•´é‡æ–°åˆ†æ
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt --full
  
  # æ¸…é™¤ä½¿ç”¨è€…ç‹€æ…‹å¾Œé‡æ–°åˆ†æ
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt --reset-state
  
  # æŒ‡å®šè¼¸å‡ºæ ¼å¼
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt csv
        """
    )
    
    parser.add_argument('filepath', help='è€ƒå‹¤æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('format', nargs='?', default='excel', 
                       choices=['excel', 'csv'], help='è¼¸å‡ºæ ¼å¼ (é è¨­: excel)')
    parser.add_argument('--incremental', '-i', action='store_true', default=True,
                       help='å•Ÿç”¨å¢é‡åˆ†ææ¨¡å¼ (é è¨­é–‹å•Ÿ)')
    parser.add_argument('--full', '-f', action='store_true',
                       help='å¼·åˆ¶å®Œæ•´é‡æ–°åˆ†æ')
    parser.add_argument('--reset-state', '-r', action='store_true',
                       help='æ¸…é™¤æŒ‡å®šä½¿ç”¨è€…çš„ç‹€æ…‹è¨˜éŒ„')
    
    args = parser.parse_args()
    
    filepath = args.filepath
    format_type = args.format
    
    # è™•ç†åˆ†ææ¨¡å¼
    incremental_mode = args.incremental and not args.full
    
    # è™•ç†ç‹€æ…‹é‡è¨­
    if args.reset_state:
        analyzer_temp = AttendanceAnalyzer()
        from lib.filename import parse_range_and_user
        from lib.state import AttendanceStateManager
        user_name, _, _ = parse_range_and_user(filepath)
        if user_name:
            state_manager = AttendanceStateManager()
            if user_name in state_manager.state_data.get("users", {}):
                del state_manager.state_data["users"][user_name]
                state_manager.save_state()
                logger.info("ğŸ—‘ï¸  ç‹€æ…‹æª” 'attendance_state.json' å·²æ¸…é™¤ä½¿ç”¨è€… %s çš„è¨˜éŒ„ @ %s", user_name, datetime.now().isoformat())
            else:
                logger.info("â„¹ï¸  ä½¿ç”¨è€… %s æ²’æœ‰ç¾æœ‰ç‹€æ…‹éœ€è¦æ¸…é™¤", user_name)
        else:
            logger.warning("âš ï¸  ç„¡æ³•å¾æª”åè­˜åˆ¥ä½¿ç”¨è€…ï¼Œç„¡æ³•åŸ·è¡Œç‹€æ…‹é‡è¨­")
            sys.exit(1)
    
    try:
        analyzer = AttendanceAnalyzer()
        
        # é¡¯ç¤ºåˆ†ææ¨¡å¼
        if incremental_mode:
            logger.info("ğŸ“‚ æ­£åœ¨è§£æè€ƒå‹¤æª”æ¡ˆ... (å¢é‡åˆ†ææ¨¡å¼)")
        else:
            logger.info("ğŸ“‚ æ­£åœ¨è§£æè€ƒå‹¤æª”æ¡ˆ... (å®Œæ•´åˆ†ææ¨¡å¼)")
            
        analyzer.parse_attendance_file(filepath, incremental=incremental_mode)
        
        logger.info("ğŸ“ æ­£åœ¨åˆ†çµ„è¨˜éŒ„...")
        analyzer.group_records_by_day()
        
        logger.info("ğŸ” æ­£åœ¨åˆ†æè€ƒå‹¤...")
        analyzer.analyze_attendance()
        
        logger.info("ğŸ“Š æ­£åœ¨ç”Ÿæˆå ±å‘Š...")
        report = analyzer.generate_report()
        
        # å¼·åˆ¶é¡¯ç¤ºå®Œæ•´å ±å‘Šï¼Œæ¯è¡Œå–®ç¨è¼¸å‡º
        logger.info("\n")
        for line in report.split('\n'):
            logger.info(line)
        
        # æ ¹æ“šæŒ‡å®šæ ¼å¼åŒ¯å‡ºï¼ˆä½¿ç”¨çµ±ä¸€ä»‹é¢ï¼ŒåŒ…å«è‡ªå‹•å‚™ä»½ï¼‰
        if format_type.lower() == 'csv':
            output_filepath = filepath.replace('.txt', '_analysis.csv')
            analyzer.export_report(output_filepath, 'csv')
            logger.info("âœ… CSVå ±å‘Šå·²åŒ¯å‡º: %s", output_filepath)
        else:
            output_filepath = filepath.replace('.txt', '_analysis.xlsx')
            analyzer.export_report(output_filepath, 'excel')
            logger.info("âœ… Excelå ±å‘Šå·²åŒ¯å‡º: %s", output_filepath)
        
        # åŒæ™‚ä¿ç•™CSVæ ¼å¼ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
        if format_type.lower() == 'excel':
            csv_filepath = filepath.replace('.txt', '_analysis.csv')
            analyzer.export_report(csv_filepath, 'csv')
            logger.info("ğŸ“ åŒæ™‚åŒ¯å‡ºCSVæ ¼å¼: %s", csv_filepath)
        
    except Exception as e:
        logger.error("âŒ éŒ¯èª¤: %s", e)
        sys.exit(1)


if __name__ == "__main__":
    main()
