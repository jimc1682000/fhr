#!/usr/bin/env python3
"""
è€ƒå‹¤åˆ†æç³»çµ±
ç”¨æ–¼åˆ†æè€ƒå‹¤è¨˜éŒ„ä¸¦è¨ˆç®—é²åˆ°/åŠ ç­æ™‚æ•¸
"""

import re
import sys
import json
import os
import logging
import time
import ssl
import random
import socket
from collections import defaultdict
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
from urllib.parse import urlparse


logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


class AttendanceType(Enum):
    CHECKIN = "ä¸Šç­"
    CHECKOUT = "ä¸‹ç­"


class IssueType(Enum):
    LATE = "é²åˆ°"
    FORGET_PUNCH = "å¿˜åˆ·å¡"
    OVERTIME = "åŠ ç­"
    WFH = "WFHå‡"
    WEEKDAY_LEAVE = "è«‹å‡"


@dataclass
class AttendanceRecord:
    date: datetime
    scheduled_time: Optional[datetime]
    actual_time: Optional[datetime]
    type: AttendanceType
    card_number: str
    source: str
    status: str
    processed: str
    operation: str
    note: str


@dataclass
class WorkDay:
    date: datetime
    checkin_record: Optional[AttendanceRecord]
    checkout_record: Optional[AttendanceRecord]
    is_friday: bool
    is_holiday: bool = False


@dataclass
class Issue:
    date: datetime
    type: IssueType
    duration_minutes: int
    description: str
    time_range: str = ""
    calculation: str = ""
    is_new: bool = True  # æ¨™ç¤ºæ˜¯å¦ç‚ºæœ¬æ¬¡æ–°ç™¼ç¾çš„å•é¡Œ


class AttendanceStateManager:
    """è€ƒå‹¤ç‹€æ…‹ç®¡ç†å™¨ - è² è²¬è®€å¯«å¢é‡åˆ†æç‹€æ…‹"""
    
    def __init__(self, state_file: str = "attendance_state.json"):
        self.state_file = state_file
        self.state_data = self._load_state()
    
    def _load_state(self) -> dict:
        """è¼‰å…¥ç‹€æ…‹æª”æ¡ˆ"""
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, OSError) as e:
                logger.warning("ç„¡æ³•è®€å–ç‹€æ…‹æª”æ¡ˆ %s: %s", self.state_file, e)
                logger.warning("å°‡ä½¿ç”¨ç©ºç™½ç‹€æ…‹")
        
        # å›å‚³é è¨­ç©ºç‹€æ…‹
        return {"users": {}}
    
    def save_state(self) -> None:
        """å„²å­˜ç‹€æ…‹åˆ°æª”æ¡ˆ"""
        try:
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(self.state_data, f, ensure_ascii=False, indent=2)
        except OSError as e:
            logger.warning("ç„¡æ³•å„²å­˜ç‹€æ…‹æª”æ¡ˆ %s: %s", self.state_file, e)
    
    def get_user_processed_ranges(self, user_name: str) -> List[Dict]:
        """å–å¾—ä½¿ç”¨è€…å·²è™•ç†çš„æ—¥æœŸç¯„åœ"""
        if user_name not in self.state_data["users"]:
            return []
        return self.state_data["users"][user_name].get("processed_date_ranges", [])
    
    def get_forget_punch_usage(self, user_name: str, year_month: str) -> int:
        """å–å¾—ä½¿ç”¨è€…åœ¨ç‰¹å®šæœˆä»½çš„å¿˜åˆ·å¡ä½¿ç”¨æ¬¡æ•¸"""
        if user_name not in self.state_data["users"]:
            return 0
        return self.state_data["users"][user_name].get("forget_punch_usage", {}).get(year_month, 0)
    
    def update_user_state(self, user_name: str, new_range: Dict[str, str], 
                         forget_punch_usage: Dict[str, int] = None) -> None:
        """æ›´æ–°ä½¿ç”¨è€…ç‹€æ…‹
        Args:
            user_name: ä½¿ç”¨è€…å§“å
            new_range: æ–°çš„æ—¥æœŸç¯„åœè³‡è¨Š {'start_date': 'YYYY-MM-DD', 'end_date': 'YYYY-MM-DD', 'source_file': 'filename', 'last_analysis_time': 'ISOæ ¼å¼æ™‚é–“'}
            forget_punch_usage: å¿˜åˆ·å¡ä½¿ç”¨çµ±è¨ˆ {'YYYY-MM': count}
        """
        if user_name not in self.state_data["users"]:
            self.state_data["users"][user_name] = {
                "processed_date_ranges": [],
                "forget_punch_usage": {}
            }
        
        user_data = self.state_data["users"][user_name]
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é‡ç–Šçš„ç¯„åœéœ€è¦åˆä½µæˆ–æ›´æ–°
        existing_ranges = user_data["processed_date_ranges"]
        updated = False
        
        for i, existing_range in enumerate(existing_ranges):
            if existing_range["source_file"] == new_range["source_file"]:
                # ç›¸åŒä¾†æºæª”æ¡ˆï¼Œæ›´æ–°è³‡è¨Š
                existing_ranges[i] = new_range
                updated = True
                break
        
        if not updated:
            # æ–°çš„ä¾†æºæª”æ¡ˆï¼ŒåŠ å…¥æ¸…å–®
            existing_ranges.append(new_range)
        
        # æ›´æ–°å¿˜åˆ·å¡ä½¿ç”¨çµ±è¨ˆ
        if forget_punch_usage:
            user_data["forget_punch_usage"].update(forget_punch_usage)
    
    def detect_date_overlap(self, user_name: str, new_start_date: str, new_end_date: str) -> List[Tuple[str, str]]:
        """æª¢æ¸¬æ–°æ—¥æœŸç¯„åœèˆ‡ç¾æœ‰ç¯„åœçš„é‡ç–Šéƒ¨åˆ†
        Args:
            user_name: ä½¿ç”¨è€…å§“å
            new_start_date: æ–°ç¯„åœé–‹å§‹æ—¥æœŸ 'YYYY-MM-DD'
            new_end_date: æ–°ç¯„åœçµæŸæ—¥æœŸ 'YYYY-MM-DD'
        Returns:
            é‡ç–Šçš„æ—¥æœŸç¯„åœæ¸…å–® [(start_date, end_date), ...]
        """
        overlaps = []
        existing_ranges = self.get_user_processed_ranges(user_name)
        
        new_start = datetime.strptime(new_start_date, "%Y-%m-%d").date()
        new_end = datetime.strptime(new_end_date, "%Y-%m-%d").date()
        
        for range_info in existing_ranges:
            existing_start = datetime.strptime(range_info["start_date"], "%Y-%m-%d").date()
            existing_end = datetime.strptime(range_info["end_date"], "%Y-%m-%d").date()
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é‡ç–Š
            if new_start <= existing_end and new_end >= existing_start:
                # è¨ˆç®—é‡ç–Šç¯„åœ
                overlap_start = max(new_start, existing_start)
                overlap_end = min(new_end, existing_end)
                overlaps.append((overlap_start.strftime("%Y-%m-%d"), overlap_end.strftime("%Y-%m-%d")))
        
        return overlaps


class AttendanceAnalyzer:
    """è€ƒå‹¤åˆ†æå™¨"""
    
    # å…¬å¸è¦å‰‡å¸¸æ•¸ï¼ˆå¯ç”±è¨­å®šæª”è¦†è“‹ï¼‰
    EARLIEST_CHECKIN = "08:30"
    LATEST_CHECKIN = "10:30"
    LUNCH_START = "12:30"
    LUNCH_END = "13:30"
    WORK_HOURS = 8
    LUNCH_HOURS = 1
    MIN_OVERTIME_MINUTES = 60
    OVERTIME_INCREMENT_MINUTES = 60  # æ”¹ç‚ºæ¯å°æ™‚ä¸€å€‹å€é–“
    FORGET_PUNCH_ALLOWANCE_PER_MONTH = 2  # æ¯æœˆå¿˜åˆ·å¡æ¬¡æ•¸
    FORGET_PUNCH_MAX_MINUTES = 60  # å¿˜åˆ·å¡æœ€å¤šå¯ç”¨æ–¼60åˆ†é˜å…§çš„é²åˆ°

    def __init__(self, config_path: str = "config.json"):
        self._load_config(config_path)
        self.records: List[AttendanceRecord] = []
        self.workdays: List[WorkDay] = []
        self.issues: List[Issue] = []
        self.holidays: set = set()  # å­˜æ”¾åœ‹å®šå‡æ—¥æ—¥æœŸ
        self.forget_punch_usage: Dict[str, int] = defaultdict(int)  # è¿½è¹¤æ¯æœˆå¿˜åˆ·å¡ä½¿ç”¨æ¬¡æ•¸ {å¹´æœˆ: æ¬¡æ•¸}
        self.loaded_holiday_years: set = set()  # è¿½è¹¤å·²è¼‰å…¥å‡æ—¥çš„å¹´ä»½
        self.state_manager: Optional[AttendanceStateManager] = None
        self.current_user: Optional[str] = None
        self.incremental_mode: bool = True

    def _load_config(self, config_path: str) -> None:
        """è¼‰å…¥è¨­å®šæª”ä»¥è¦†è“‹é è¨­å…¬å¸è¦å‰‡"""
        if not os.path.exists(config_path):
            logger.info("æ‰¾ä¸åˆ°è¨­å®šæª” %sï¼Œä½¿ç”¨é è¨­å€¼", config_path)
            return
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for key, value in data.items():
                if hasattr(self, key):
                    setattr(self, key, value)
        except (OSError, json.JSONDecodeError) as e:
            logger.warning("ç„¡æ³•è®€å–è¨­å®šæª” %s: %s", config_path, e)
    
    def _extract_user_and_date_range_from_filename(self, filepath: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """å¾æª”æ¡ˆåç¨±è§£æä½¿ç”¨è€…å§“åå’Œæ—¥æœŸç¯„åœ
        æ”¯æ´æ ¼å¼: {YYYYMM}[-{YYYYMM}]-{NAME}-å‡ºå‹¤è³‡æ–™.txt
        
        Args:
            filepath: æª”æ¡ˆè·¯å¾‘
        
        Returns:
            Tuple[ä½¿ç”¨è€…å§“å, é–‹å§‹æ—¥æœŸYYYY-MM-DD, çµæŸæ—¥æœŸYYYY-MM-DD]
        """
        filename = os.path.basename(filepath)
        
        # åŒ¹é…æ¨¡å¼: YYYYMM[-YYYYMM]-NAME-å‡ºå‹¤è³‡æ–™.txt
        pattern = r'(\d{6})(?:-(\d{6}))?-(.+?)-å‡ºå‹¤è³‡æ–™\.txt$'
        match = re.match(pattern, filename)
        
        if not match:
            logger.warning("æª”æ¡ˆåç¨±æ ¼å¼ä¸ç¬¦åˆè¦ç¯„: %s", filename)
            logger.warning("é æœŸæ ¼å¼: YYYYMM[-YYYYMM]-å§“å-å‡ºå‹¤è³‡æ–™.txt")
            return None, None, None
        
        start_month_str = match.group(1)  # YYYYMM
        end_month_str = match.group(2)    # YYYYMM æˆ– None
        user_name = match.group(3)        # å§“å
        
        # è§£æé–‹å§‹æ—¥æœŸ
        try:
            start_year = int(start_month_str[:4])
            start_month = int(start_month_str[4:6])
            start_date = datetime(start_year, start_month, 1).strftime("%Y-%m-%d")
        except ValueError:
            logger.warning("ç„¡æ³•è§£æé–‹å§‹æœˆä»½: %s", start_month_str)
            return None, None, None
        
        # è§£æçµæŸæ—¥æœŸ
        if end_month_str:
            # è·¨æœˆæª”æ¡ˆ
            try:
                end_year = int(end_month_str[:4])
                end_month = int(end_month_str[4:6])
                # å–è©²æœˆæœ€å¾Œä¸€å¤©
                if end_month == 12:
                    next_month = datetime(end_year + 1, 1, 1)
                else:
                    next_month = datetime(end_year, end_month + 1, 1)
                end_date = (next_month - timedelta(days=1)).strftime("%Y-%m-%d")
            except ValueError:
                logger.warning("ç„¡æ³•è§£æçµæŸæœˆä»½: %s", end_month_str)
                return None, None, None
        else:
            # å–®æœˆæª”æ¡ˆ
            try:
                # å–è©²æœˆæœ€å¾Œä¸€å¤©
                if start_month == 12:
                    next_month = datetime(start_year + 1, 1, 1)
                else:
                    next_month = datetime(start_year, start_month + 1, 1)
                end_date = (next_month - timedelta(days=1)).strftime("%Y-%m-%d")
            except ValueError:
                logger.warning("ç„¡æ³•è¨ˆç®—æœˆä»½çµæŸæ—¥æœŸ")
                return None, None, None
        
        return user_name, start_date, end_date
    
    def _identify_complete_work_days(self) -> List[datetime]:
        """è­˜åˆ¥å®Œæ•´çš„å·¥ä½œæ—¥ï¼ˆæœ‰ä¸Šç­å’Œä¸‹ç­è¨˜éŒ„çš„æ—¥æœŸï¼‰
        Returns:
            å®Œæ•´å·¥ä½œæ—¥çš„æ—¥æœŸæ¸…å–®
        """
        complete_days = []
        daily_records = defaultdict(lambda: {'checkin': False, 'checkout': False})

        # æŒ‰æ—¥æœŸåˆ†çµ„è¨˜éŒ„
        for record in self.records:
            if not record.date:
                continue

            if record.type == AttendanceType.CHECKIN:
                daily_records[record.date]['checkin'] = True
            else:
                daily_records[record.date]['checkout'] = True
        
        # æ‰¾å‡ºæœ‰ä¸Šç­å’Œä¸‹ç­è¨˜éŒ„çš„å®Œæ•´å·¥ä½œæ—¥
        for date, records in daily_records.items():
            if records['checkin'] and records['checkout']:
                complete_days.append(datetime.combine(date, datetime.min.time()))
        
        return sorted(complete_days)
    
    def _get_unprocessed_dates(self, user_name: str, complete_days: List[datetime]) -> List[datetime]:
        """å–å¾—éœ€è¦è™•ç†çš„æ–°æ—¥æœŸï¼ˆæ’é™¤å·²è™•ç†çš„é‡ç–Šæ—¥æœŸï¼‰
        Args:
            user_name: ä½¿ç”¨è€…å§“å
            complete_days: å®Œæ•´å·¥ä½œæ—¥æ¸…å–®
        Returns:
            éœ€è¦è™•ç†çš„æ—¥æœŸæ¸…å–®
        """
        if not self.state_manager or not self.incremental_mode:
            return complete_days
        
        processed_ranges = self.state_manager.get_user_processed_ranges(user_name)
        unprocessed_dates = []
        
        for day in complete_days:
            day_str = day.strftime("%Y-%m-%d")
            is_processed = False
            
            # æª¢æŸ¥é€™å€‹æ—¥æœŸæ˜¯å¦å·²åœ¨ä¹‹å‰è™•ç†éçš„ç¯„åœå…§
            for range_info in processed_ranges:
                if range_info["start_date"] <= day_str <= range_info["end_date"]:
                    is_processed = True
                    break
            
            if not is_processed:
                unprocessed_dates.append(day)
        
        return unprocessed_dates
    
    def _load_previous_forget_punch_usage(self, user_name: str) -> None:
        """è¼‰å…¥ä¹‹å‰çš„å¿˜åˆ·å¡ä½¿ç”¨çµ±è¨ˆ"""
        if not self.state_manager or not self.incremental_mode:
            return
        
        # æ¸…ç©ºç¾æœ‰çµ±è¨ˆ
        self.forget_punch_usage = defaultdict(int)
        
        # å¾ç‹€æ…‹ç®¡ç†å™¨è¼‰å…¥
        user_data = self.state_manager.state_data.get("users", {}).get(user_name, {})
        previous_usage = user_data.get("forget_punch_usage", {})
        
        # è¤‡è£½åˆ°æœ¬åœ°çµ±è¨ˆ
        self.forget_punch_usage.update(previous_usage)
    
    def _get_years_from_records(self) -> set:
        """å¾å‡ºå‹¤è¨˜éŒ„ä¸­æå–å¹´ä»½"""
        years = set()
        for record in self.records:
            if record.date:
                years.add(record.date.year)
        return years
    
    def _load_taiwan_holidays(self, years: set = None) -> None:
        """è¼‰å…¥å°ç£åœ‹å®šå‡æ—¥è³‡æ–™
        Args:
            years: éœ€è¦è¼‰å…¥çš„å¹´ä»½é›†åˆï¼ŒNoneè¡¨ç¤ºåªè¼‰å…¥ç•¶å¹´(2025)
        """
        if years is None:
            years = {2025}  # é è¨­è¼‰å…¥ç•¶å¹´
        
        for year in years:
            if year not in self.loaded_holiday_years:
                if year == 2025:
                    self._load_hardcoded_2025_holidays()
                else:
                    self._load_dynamic_holidays(year)
                self.loaded_holiday_years.add(year)
    
    def _load_hardcoded_2025_holidays(self) -> None:
        """è¼‰å…¥ç¡¬ç·¨ç¢¼çš„2025å¹´åœ‹å®šå‡æ—¥ï¼ˆé«˜æ•ˆèƒ½ï¼‰"""
        # 2025å¹´(æ°‘åœ‹114å¹´)åœ‹å®šå‡æ—¥æ¸…å–®
        taiwan_holidays_2025 = [
            # å…ƒæ—¦é€£å‡
            "2025/01/01",
            # è¾²æ›†æ˜¥ç¯€
            "2025/01/25", "2025/01/26", "2025/01/27", "2025/01/28", "2025/01/29", "2025/01/30", "2025/01/31", "2025/02/01", "2025/02/02",
            # å’Œå¹³ç´€å¿µæ—¥
            "2025/02/28", "2025/03/01", "2025/03/02",
            # å…’ç«¥ç¯€/æ¸…æ˜ç¯€
            "2025/04/03", "2025/04/04", "2025/04/05", "2025/04/06",
            # ç«¯åˆç¯€
            "2025/05/30", "2025/05/31", "2025/06/01",
            # ä¸­ç§‹ç¯€
            "2025/10/04", "2025/10/05", "2025/10/06",
            # åœ‹æ…¶æ—¥
            "2025/10/10", "2025/10/11", "2025/10/12",
        ]
        
        for holiday_str in taiwan_holidays_2025:
            try:
                holiday_date = datetime.strptime(holiday_str, "%Y/%m/%d").date()
                self.holidays.add(holiday_date)
            except ValueError:
                logger.warning("ç„¡æ³•è§£æåœ‹å®šå‡æ—¥æ—¥æœŸ: %s", holiday_str)
    
    def _load_dynamic_holidays(self, year: int) -> None:
        """å‹•æ…‹è¼‰å…¥æŒ‡å®šå¹´ä»½çš„åœ‹å®šå‡æ—¥
        Args:
            year: è¦è¼‰å…¥çš„å¹´ä»½
        """
        logger.info("è³‡è¨Š: å‹•æ…‹è¼‰å…¥ %d å¹´åœ‹å®šå‡æ—¥...", year)
        
        # æ–¹æ¡ˆ1: ä½¿ç”¨æ”¿åºœé–‹æ”¾è³‡æ–™API
        success = self._try_load_from_gov_api(year)
        
        if not success:
            # æ–¹æ¡ˆ2: ä½¿ç”¨åŸºæœ¬å‡æ—¥è¦å‰‡ï¼ˆå…ƒæ—¦ã€åœ‹æ…¶æ—¥ç­‰å›ºå®šæ—¥æœŸï¼‰
            self._load_basic_holidays(year)
            logger.warning("ç„¡æ³•å–å¾— %d å¹´å®Œæ•´å‡æ—¥è³‡æ–™ï¼Œåƒ…è¼‰å…¥åŸºæœ¬å›ºå®šå‡æ—¥", year)
    
    def _try_load_from_gov_api(self, year: int) -> bool:
        """å˜—è©¦å¾æ”¿åºœé–‹æ”¾è³‡æ–™APIè¼‰å…¥å‡æ—¥
        Args:
            year: è¦è¼‰å…¥çš„å¹´ä»½
        Returns:
            bool: æ˜¯å¦æˆåŠŸè¼‰å…¥
        """
        import urllib.request
        import urllib.error
        import json as _json
        from urllib.error import URLError, HTTPError

        # APIè¨­å®š
        url = "https://data.gov.tw/api/v1/rest/datastore_search?resource_id=W2&filters={\"date\":\"%s\"}" % year
        parsed = urlparse(url)
        if parsed.scheme not in {"http", "https"}:
            logger.warning("ä¸æ”¯æ´çš„ URL scheme: %s", parsed.scheme)
            return False
        context = ssl.create_default_context()

        # é‡è©¦èˆ‡é€€é¿åƒæ•¸
        try:
            max_retries = int(os.getenv("HOLIDAY_API_MAX_RETRIES", "3"))
        except ValueError:
            max_retries = 3
        try:
            base_backoff = float(os.getenv("HOLIDAY_API_BACKOFF_BASE", "0.5"))
        except ValueError:
            base_backoff = 0.5
        try:
            max_backoff = float(os.getenv("HOLIDAY_API_MAX_BACKOFF", "8"))
        except ValueError:
            max_backoff = 8.0

        attempt = 0
        while attempt <= max_retries:
            attempt += 1
            try:
                logger.info("è³‡è¨Š: å˜—è©¦è¼‰å…¥ %d å¹´å‡æ—¥ (ç¬¬ %d/%d æ¬¡)...", year, attempt, max_retries)
                with urllib.request.urlopen(url, timeout=10, context=context) as response:  # nosec B310
                    data = _json.loads(response.read().decode('utf-8'))
                    if 'result' in data and 'records' in data['result']:
                        added = 0
                        for record in data['result']['records']:
                            if record.get('isHoliday', 0) == 1:
                                date_str = record.get('date', '')
                                if date_str:
                                    try:
                                        holiday_date = datetime.strptime(date_str, "%Y-%m-%d").date()
                                        self.holidays.add(holiday_date)
                                        added += 1
                                    except ValueError as e:
                                        logger.warning("è·³éç„¡æ•ˆçš„æ—¥æœŸæ ¼å¼ %r: %s", date_str, e)
                        if added > 0:
                            return True
                        logger.warning("API å›å‚³è³‡æ–™ä½†æ²’æœ‰æœ‰æ•ˆçš„å‡æ—¥è¨˜éŒ„")
                        # è¦–ç‚ºå¯é‡è©¦
                        raise RuntimeError("empty holiday records")
            except HTTPError as e:
                status = getattr(e, 'code', None)
                if status in (429, 500, 502, 503, 504):
                    err_desc = f"HTTP {status}"
                else:
                    logger.warning("ç„¡æ³•å¾APIè¼‰å…¥ %d å¹´å‡æ—¥è³‡æ–™: HTTP %s â€” ä¸é‡è©¦ã€‚", year, status)
                    return False
            except (URLError, socket.timeout, TimeoutError, _json.JSONDecodeError, ValueError) as e:
                err_desc = f"é€£ç·š/è§£æéŒ¯èª¤: {e}"
            except Exception as e:
                err_desc = f"ä¸€èˆ¬éŒ¯èª¤: {e}"

            if attempt > max_retries:
                logger.error("éŒ¯èª¤: å˜—è©¦ %d æ¬¡å¾Œä»ç„¡æ³•è¼‰å…¥ %d å¹´å‡æ—¥è³‡æ–™ã€‚å›é€€åˆ°åŸºæœ¬å‡æ—¥ã€‚", max_retries, year)
                break

            sleep_s = min(max_backoff, base_backoff * (2 ** (attempt - 1)))
            jitter = sleep_s * random.uniform(-0.1, 0.1)
            wait_s = max(0.0, sleep_s + jitter)
            logger.warning("%sï¼Œ%.2f ç§’å¾Œé‡è©¦...", err_desc, wait_s)
            time.sleep(wait_s)

        return False

    def _load_basic_holidays(self, year: int) -> None:
        """è¼‰å…¥åŸºæœ¬å›ºå®šå‡æ—¥ï¼ˆç•¶APIä¸å¯ç”¨æ™‚çš„å‚™æ¡ˆï¼‰
        Args:
            year: è¦è¼‰å…¥çš„å¹´ä»½
        """
        basic_holidays = [
            f"{year}/01/01",  # å…ƒæ—¦
            f"{year}/10/10",  # åœ‹æ…¶æ—¥
        ]
        
        for holiday_str in basic_holidays:
            try:
                holiday_date = datetime.strptime(holiday_str, "%Y/%m/%d").date()
                self.holidays.add(holiday_date)
            except ValueError:
                logger.warning("ç„¡æ³•è§£æåŸºæœ¬å‡æ—¥æ—¥æœŸ: %s", holiday_str)
    
    def parse_attendance_file(self, filepath: str, incremental: bool = True) -> None:
        """è§£æè€ƒå‹¤è³‡æ–™æª”æ¡ˆä¸¦åˆå§‹åŒ–å¢é‡è™•ç†
        Args:
            filepath: æª”æ¡ˆè·¯å¾‘
            incremental: æ˜¯å¦å•Ÿç”¨å¢é‡åˆ†æ
        """
        self.incremental_mode = incremental
        
        # åˆå§‹åŒ–ç‹€æ…‹ç®¡ç†å™¨
        if self.incremental_mode:
            self.state_manager = AttendanceStateManager()
            
            # è§£ææª”åå–å¾—ä½¿ç”¨è€…è³‡è¨Š
            user_name, start_date, end_date = self._extract_user_and_date_range_from_filename(filepath)
            if user_name:
                self.current_user = user_name
                logger.info("ğŸ“‹ è­˜åˆ¥ä½¿ç”¨è€…: %s", user_name)
                logger.info("ğŸ“… æª”æ¡ˆæ¶µè“‹æœŸé–“: %s è‡³ %s", start_date, end_date)
                
                # æª¢æŸ¥é‡ç–Šæ—¥æœŸ
                if start_date and end_date:
                    overlaps = self.state_manager.detect_date_overlap(user_name, start_date, end_date)
                    if overlaps:
                        logger.warning("âš ï¸  ç™¼ç¾é‡ç–Šæ—¥æœŸç¯„åœ: %s", overlaps)
                        logger.warning("å°‡ä»¥èˆŠè³‡æ–™ç‚ºä¸»ï¼Œåƒ…è™•ç†æ–°æ—¥æœŸ")
                
                # è¼‰å…¥ä¹‹å‰çš„å¿˜åˆ·å¡ä½¿ç”¨çµ±è¨ˆ
                self._load_previous_forget_punch_usage(user_name)
            else:
                logger.warning("âš ï¸  ç„¡æ³•å¾æª”åè­˜åˆ¥ä½¿ç”¨è€…ï¼Œå°‡ä½¿ç”¨å®Œæ•´åˆ†ææ¨¡å¼")
                self.incremental_mode = False
        
        # è§£ææª”æ¡ˆå…§å®¹
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        for line_num, line in enumerate(lines, 1):
            if line_num == 1:  # è·³éè¡¨é ­
                continue
                
            line = line.strip()
            if not line:
                continue
                
            try:
                record = self._parse_attendance_line(line)
                if record:
                    self.records.append(record)
            except (ValueError, IndexError) as e:
                logger.warning("ç¬¬%dè¡Œè§£æå¤±æ•—: %s", line_num, e)
    
    def _parse_attendance_line(self, line: str) -> Optional[AttendanceRecord]:
        """è§£æå–®è¡Œè€ƒå‹¤è¨˜éŒ„"""
        # ç§»é™¤è¡Œè™Ÿå‰ç¶´
        line = re.sub(r'^\s*\d+â†’', '', line)
        
        # åˆ†å‰²æ¬„ä½
        fields = line.split('\t')
        if len(fields) < 3:
            return None
        
        # è£œé½Šæ¬„ä½åˆ°9å€‹
        while len(fields) < 9:
            fields.append('')
        
        scheduled_str, actual_str, type_str = fields[0], fields[1], fields[2]
        card_num, source, status = fields[3], fields[4], fields[5]
        processed, operation, note = fields[6], fields[7], fields[8]
        
        # è§£ææ—¥æœŸæ™‚é–“
        scheduled_time = self._parse_datetime(scheduled_str) if scheduled_str else None
        actual_time = self._parse_datetime(actual_str) if actual_str else None
        
        # è·³éç„¡æ•ˆè¨˜éŒ„
        if not scheduled_time or type_str not in ["ä¸Šç­", "ä¸‹ç­"]:
            return None
        
        # è§£æè€ƒå‹¤é¡å‹
        attendance_type = AttendanceType.CHECKIN if type_str == "ä¸Šç­" else AttendanceType.CHECKOUT
        
        return AttendanceRecord(
            date=scheduled_time.date() if scheduled_time else None,
            scheduled_time=scheduled_time,
            actual_time=actual_time,
            type=attendance_type,
            card_number=card_num,
            source=source,
            status=status,
            processed=processed,
            operation=operation,
            note=note
        )
    
    def _parse_datetime(self, datetime_str: str) -> Optional[datetime]:
        """è§£ææ—¥æœŸæ™‚é–“å­—ä¸²"""
        try:
            return datetime.strptime(datetime_str, "%Y/%m/%d %H:%M")
        except ValueError:
            return None
    
    def group_records_by_day(self) -> None:
        """å°‡è¨˜éŒ„æŒ‰æ—¥æœŸåˆ†çµ„"""
        # åœ¨åˆ†çµ„å‰ï¼Œå…ˆè¼‰å…¥å‡ºå‹¤è³‡æ–™ä¸­æ¶‰åŠçš„å¹´ä»½å‡æ—¥
        years_in_data = self._get_years_from_records()
        if years_in_data:
            self._load_taiwan_holidays(years_in_data)
        
        daily_records = defaultdict(lambda: {'checkin': None, 'checkout': None})

        for record in self.records:
            if not record.date:
                continue

            if record.type == AttendanceType.CHECKIN:
                daily_records[record.date]['checkin'] = record
            else:
                daily_records[record.date]['checkout'] = record
        
        for date, records in daily_records.items():
            workday = WorkDay(
                date=datetime.combine(date, datetime.min.time()),
                checkin_record=records['checkin'],
                checkout_record=records['checkout'],
                is_friday=(date.weekday() == 4),  # é€±äº”æ˜¯4
                is_holiday=(date in self.holidays)  # æª¢æŸ¥æ˜¯å¦ç‚ºåœ‹å®šå‡æ—¥
            )
            self.workdays.append(workday)
        
        self.workdays.sort(key=lambda x: x.date)
    
    def analyze_attendance(self) -> None:
        """åˆ†æè€ƒå‹¤è¨˜éŒ„ï¼ˆæ”¯æ´å¢é‡åˆ†æï¼‰"""
        self.issues = []
        
        # å¢é‡åˆ†ææ¨¡å¼ï¼šåªåˆ†ææ–°çš„å®Œæ•´å·¥ä½œæ—¥
        if self.incremental_mode and self.current_user:
            complete_days = self._identify_complete_work_days()
            unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
            
            if unprocessed_dates:
                logger.info("ğŸ”„ å¢é‡åˆ†æ: ç™¼ç¾ %d å€‹æ–°çš„å®Œæ•´å·¥ä½œæ—¥éœ€è¦è™•ç†", len(unprocessed_dates))
                logger.info("ğŸ“Š è·³éå·²è™•ç†çš„å·¥ä½œæ—¥: %d å€‹", len(complete_days) - len(unprocessed_dates))
                
                # åªåˆ†ææœªè™•ç†çš„å·¥ä½œæ—¥
                unprocessed_date_set = {d.date() for d in unprocessed_dates}
                workdays_to_analyze = [wd for wd in self.workdays if wd.date.date() in unprocessed_date_set]
            else:
                logger.info("âœ… å¢é‡åˆ†æ: æ²’æœ‰æ–°çš„å·¥ä½œæ—¥éœ€è¦è™•ç†")
                workdays_to_analyze = []
        else:
            # å®Œæ•´åˆ†ææ¨¡å¼ï¼šåˆ†ææ‰€æœ‰å·¥ä½œæ—¥
            workdays_to_analyze = self.workdays
        
        for workday in workdays_to_analyze:
            # æª¢æŸ¥æ˜¯å¦æ•´å¤©æ²’æœ‰æ‰“å¡è¨˜éŒ„ï¼ˆæ› è·ï¼‰
            if self._is_full_day_absent(workday):
                if workday.is_friday and not workday.is_holiday:
                    # é€±äº”ä¸”éåœ‹å®šå‡æ—¥å»ºè­°WFHå‡
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.WFH,
                        duration_minutes=9 * 60,  # 9å°æ™‚
                        description="å»ºè­°ç”³è«‹æ•´å¤©WFHå‡ ğŸ ğŸ’»"
                    ))
                elif not workday.is_holiday:
                    # éåœ‹å®šå‡æ—¥çš„é€±ä¸€åˆ°é€±å››å»ºè­°è«‹å‡
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.WEEKDAY_LEAVE,
                        duration_minutes=8 * 60,  # 8å°æ™‚
                        description="æ•´å¤©æ²’é€²å…¬å¸ï¼Œå»ºè­°è«‹å‡ ğŸ“ğŸ "
                    ))
                # å¦‚æœæ˜¯åœ‹å®šå‡æ—¥ï¼Œå‰‡ä¸éœ€è¦ä»»ä½•ç”³è«‹å»ºè­°
                continue
            
            if workday.is_friday:
                # é€±äº”å·²è™•ç†ï¼Œè·³éåˆ†æ
                continue
            
            # åˆ†æé²åˆ°
            late_minutes, late_time_range, late_calculation = self._calculate_late_minutes(workday)
            if late_minutes > 0:
                # æª¢æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨å¿˜åˆ·å¡
                month_key = workday.date.strftime('%Y-%m')
                can_use_forget_punch = (
                    late_minutes <= self.FORGET_PUNCH_MAX_MINUTES and
                    self.forget_punch_usage[month_key] < self.FORGET_PUNCH_ALLOWANCE_PER_MONTH
                )
                
                if can_use_forget_punch:
                    # ä½¿ç”¨å¿˜åˆ·å¡
                    self.forget_punch_usage[month_key] += 1
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.FORGET_PUNCH,
                        duration_minutes=0,  # å¿˜åˆ·å¡ä¸éœ€è¦è«‹å‡
                        description=f"é²åˆ°{late_minutes}åˆ†é˜ï¼Œå»ºè­°ä½¿ç”¨å¿˜åˆ·å¡ ğŸ”„âœ…",
                        time_range=late_time_range,
                        calculation=f"{late_calculation} (ä½¿ç”¨å¿˜åˆ·å¡ï¼Œæœ¬æœˆå‰©é¤˜: {self.FORGET_PUNCH_ALLOWANCE_PER_MONTH - self.forget_punch_usage[month_key]}æ¬¡)"
                    ))
                else:
                    # éœ€è¦è«‹é²åˆ°å‡
                    reason = "è¶…é1å°æ™‚" if late_minutes > self.FORGET_PUNCH_MAX_MINUTES else f"æœ¬æœˆå¿˜åˆ·å¡é¡åº¦å·²ç”¨å®Œ"
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.LATE,
                        duration_minutes=late_minutes,
                        description=f"é²åˆ°{late_minutes}åˆ†é˜ â±ï¸ ({reason})",
                        time_range=late_time_range,
                        calculation=late_calculation
                    ))
            
            # åˆ†æåŠ ç­
            actual_overtime, applicable_overtime, overtime_time_range, overtime_calculation = self._calculate_overtime_minutes(workday)
            if applicable_overtime >= self.MIN_OVERTIME_MINUTES:
                self.issues.append(Issue(
                    date=workday.date,
                    type=IssueType.OVERTIME,
                    duration_minutes=applicable_overtime,
                    description=f"åŠ ç­{applicable_overtime // 60}å°æ™‚{applicable_overtime % 60}åˆ†é˜ ğŸ’¼",
                    time_range=overtime_time_range,
                    calculation=overtime_calculation
                ))
        
        # å¢é‡åˆ†ææ¨¡å¼ï¼šæ›´æ–°ç‹€æ…‹
        if self.incremental_mode and self.current_user and workdays_to_analyze:
            self._update_processing_state()
    
    def _update_processing_state(self) -> None:
        """æ›´æ–°è™•ç†ç‹€æ…‹åˆ°ç‹€æ…‹æª”æ¡ˆ"""
        if not self.state_manager or not self.current_user:
            return
        
        # è¨ˆç®—è™•ç†ç¯„åœ
        complete_days = self._identify_complete_work_days()
        if not complete_days:
            return
        
        start_date = min(complete_days).strftime("%Y-%m-%d")
        end_date = max(complete_days).strftime("%Y-%m-%d")
        
        # æ§‹å»ºç¯„åœè³‡è¨Š
        range_info = {
            "start_date": start_date,
            "end_date": end_date,
            "source_file": os.path.basename(sys.argv[1]) if len(sys.argv) > 1 else "unknown",
            "last_analysis_time": datetime.now().isoformat()
        }
        
        # æ›´æ–°ç‹€æ…‹
        self.state_manager.update_user_state(
            self.current_user,
            range_info,
            self.forget_punch_usage
        )
        
        # å„²å­˜ç‹€æ…‹æª”æ¡ˆ
        self.state_manager.save_state()
        logger.info("ğŸ’¾ å·²æ›´æ–°è™•ç†ç‹€æ…‹: %s è‡³ %s", start_date, end_date)
    
    def _calculate_late_minutes(self, workday: WorkDay) -> tuple:
        """è¨ˆç®—é²åˆ°åˆ†é˜æ•¸ï¼Œè¿”å› (åˆ†é˜æ•¸, æ™‚æ®µ, è¨ˆç®—å¼)"""
        if not workday.checkin_record or not workday.checkin_record.actual_time:
            return 0, "", ""
        
        latest_checkin = datetime.strptime(f"{workday.date.strftime('%Y/%m/%d')} {self.LATEST_CHECKIN}", "%Y/%m/%d %H:%M")
        actual_checkin = workday.checkin_record.actual_time
        
        if actual_checkin > latest_checkin:
            delta = actual_checkin - latest_checkin
            late_minutes = int(delta.total_seconds() // 60)
            
            # å¦‚æœé²åˆ°è¶…é2å°æ™‚ï¼Œéœ€è¦æ‰£é™¤åˆä¼‘æ™‚é–“
            if late_minutes > 120:  # è¶…é2å°æ™‚
                lunch_start = datetime.strptime(f"{workday.date.strftime('%Y/%m/%d')} {self.LUNCH_START}", "%Y/%m/%d %H:%M")
                lunch_end = datetime.strptime(f"{workday.date.strftime('%Y/%m/%d')} {self.LUNCH_END}", "%Y/%m/%d %H:%M")
                
                # å¦‚æœä¸Šç­æ™‚é–“è·¨è¶Šåˆä¼‘æ™‚æ®µï¼Œæ‰£é™¤åˆä¼‘æ™‚é–“
                if actual_checkin > lunch_start:
                    late_minutes -= 60  # æ‰£é™¤1å°æ™‚åˆä¼‘
                    calculation = f"å¯¦éš›ä¸Šç­: {actual_checkin.strftime('%H:%M')}, æœ€æ™šä¸Šç­: {self.LATEST_CHECKIN}, é²åˆ°: {int(delta.total_seconds() // 60)}åˆ†é˜ - 60åˆ†é˜åˆä¼‘ = {late_minutes}åˆ†é˜"
                else:
                    calculation = f"å¯¦éš›ä¸Šç­: {actual_checkin.strftime('%H:%M')}, æœ€æ™šä¸Šç­: {self.LATEST_CHECKIN}, é²åˆ°: {late_minutes}åˆ†é˜"
            else:
                calculation = f"å¯¦éš›ä¸Šç­: {actual_checkin.strftime('%H:%M')}, æœ€æ™šä¸Šç­: {self.LATEST_CHECKIN}, é²åˆ°: {late_minutes}åˆ†é˜"
            
            time_range = f"{self.LATEST_CHECKIN}~{actual_checkin.strftime('%H:%M')}"
            return late_minutes, time_range, calculation
        
        return 0, "", ""
    
    def _calculate_overtime_minutes(self, workday: WorkDay) -> tuple:
        """è¨ˆç®—åŠ ç­åˆ†é˜æ•¸ï¼Œè¿”å› (å¯¦éš›åˆ†é˜æ•¸, å¯ç”³è«‹åˆ†é˜æ•¸, æ™‚æ®µ, è¨ˆç®—å¼)"""
        if (not workday.checkin_record or not workday.checkin_record.actual_time or
            not workday.checkout_record or not workday.checkout_record.actual_time):
            return 0, 0, "", ""
        
        checkin_time = workday.checkin_record.actual_time
        checkout_time = workday.checkout_record.actual_time
        
        # è¨ˆç®—æ‡‰ä¸‹ç­æ™‚é–“ = ä¸Šç­æ™‚é–“ + 8å°æ™‚å·¥ä½œ + 1å°æ™‚åˆä¼‘
        expected_checkout = checkin_time + timedelta(hours=self.WORK_HOURS + self.LUNCH_HOURS)
        
        if checkout_time > expected_checkout:
            delta = checkout_time - expected_checkout
            actual_overtime_minutes = int(delta.total_seconds() // 60)
            
            # æŒ‰åŠå°æ™‚é–“éš”è¨ˆç®—å¯ç”³è«‹æ™‚æ•¸
            if actual_overtime_minutes >= self.MIN_OVERTIME_MINUTES:
                # è¨ˆç®—å¯ç”³è«‹çš„åŠå°æ™‚é–“éš”æ•¸
                intervals = (actual_overtime_minutes - self.MIN_OVERTIME_MINUTES) // self.OVERTIME_INCREMENT_MINUTES
                applicable_minutes = self.MIN_OVERTIME_MINUTES + (intervals * self.OVERTIME_INCREMENT_MINUTES)
                
                time_range = f"{expected_checkout.strftime('%H:%M')}~{checkout_time.strftime('%H:%M')}"
                calculation = f"é æœŸä¸‹ç­: {expected_checkout.strftime('%H:%M')}, å¯¦éš›ä¸‹ç­: {checkout_time.strftime('%H:%M')}, å¯¦éš›åŠ ç­: {actual_overtime_minutes}åˆ†é˜, å¯ç”³è«‹: {applicable_minutes}åˆ†é˜"
                
                return actual_overtime_minutes, applicable_minutes, time_range, calculation
        
        return 0, 0, "", ""
    
    def _is_full_day_absent(self, workday: WorkDay) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ•´å¤©æ²’æœ‰æ‰“å¡è¨˜éŒ„"""
        # å¦‚æœæ²’æœ‰ä¸Šç­è¨˜éŒ„æˆ–ä¸Šç­è¨˜éŒ„æ²’æœ‰å¯¦éš›æ‰“å¡æ™‚é–“ï¼Œè¦–ç‚ºæ•´å¤©æ› è·
        if (not workday.checkin_record or 
            not workday.checkin_record.actual_time):
            return True
        
        # å¦‚æœæ²’æœ‰ä¸‹ç­è¨˜éŒ„æˆ–ä¸‹ç­è¨˜éŒ„æ²’æœ‰å¯¦éš›æ‰“å¡æ™‚é–“ï¼Œä¹Ÿè¦–ç‚ºæ› è·
        if (not workday.checkout_record or 
            not workday.checkout_record.actual_time):
            return True
            
        return False
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå ±å‘Šï¼ˆæ”¯æ´å¢é‡åˆ†æè³‡è¨Šé¡¯ç¤ºï¼‰"""
        report = []
        report.append("# ğŸ¯ è€ƒå‹¤åˆ†æå ±å‘Š âœ¨\n")
        
        # é¡¯ç¤ºå¢é‡åˆ†æè³‡è¨Š
        if self.incremental_mode and self.current_user:
            complete_days = self._identify_complete_work_days()
            unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
            
            report.append("## ğŸ“ˆ å¢é‡åˆ†æè³‡è¨Šï¼š\n")
            report.append(f"- ğŸ‘¤ ä½¿ç”¨è€…ï¼š{self.current_user}")
            report.append(f"- ğŸ“Š ç¸½å®Œæ•´å·¥ä½œæ—¥ï¼š{len(complete_days)} å¤©")
            report.append(f"- ğŸ”„ æ–°è™•ç†å·¥ä½œæ—¥ï¼š{len(unprocessed_dates)} å¤©")
            report.append(f"- â­ï¸  è·³éå·²è™•ç†ï¼š{len(complete_days) - len(unprocessed_dates)} å¤©")
            
            if unprocessed_dates:
                new_dates_str = ", ".join([d.strftime('%Y/%m/%d') for d in unprocessed_dates[:5]])
                if len(unprocessed_dates) > 5:
                    new_dates_str += f" ç­‰ {len(unprocessed_dates)} å¤©"
                report.append(f"- ğŸ“… æ–°è™•ç†æ—¥æœŸï¼š{new_dates_str}")
            report.append("")
        
        # å¿˜åˆ·å¡å»ºè­°
        forget_punch_issues = [issue for issue in self.issues if issue.type == IssueType.FORGET_PUNCH]
        if forget_punch_issues:
            report.append("## ğŸ”„ å»ºè­°ä½¿ç”¨å¿˜åˆ·å¡çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(forget_punch_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ”„ {issue.description}")
                report.append(f"   â° æ™‚æ®µ: {issue.time_range}")
                report.append(f"   ğŸ§® è¨ˆç®—: {issue.calculation}")
                report.append("")
        
        # é²åˆ°çµ±è¨ˆ
        late_issues = [issue for issue in self.issues if issue.type == IssueType.LATE]
        if late_issues:
            report.append("## ğŸ˜° éœ€è¦è«‹é²åˆ°çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(late_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ˜… {issue.description}")
                report.append(f"   â° æ™‚æ®µ: {issue.time_range}")
                report.append(f"   ğŸ§® è¨ˆç®—: {issue.calculation}")
                report.append("")
        
        # åŠ ç­çµ±è¨ˆ
        overtime_issues = [issue for issue in self.issues if issue.type == IssueType.OVERTIME]
        if overtime_issues:
            report.append("## ğŸ’ª éœ€è¦è«‹åŠ ç­çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(overtime_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ”¥ {issue.description}")
                report.append(f"   â° æ™‚æ®µ: {issue.time_range}")
                report.append(f"   ğŸ§® è¨ˆç®—: {issue.calculation}")
                report.append("")
        
        # é€±ä¸€åˆ°é€±å››è«‹å‡å»ºè­°
        weekday_leave_issues = [issue for issue in self.issues if issue.type == IssueType.WEEKDAY_LEAVE]
        if weekday_leave_issues:
            report.append("## ğŸ“ éœ€è¦è«‹å‡çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(weekday_leave_issues, 1):
                weekday_name = ['é€±ä¸€', 'é€±äºŒ', 'é€±ä¸‰', 'é€±å››', 'é€±äº”', 'é€±å…­', 'é€±æ—¥'][issue.date.weekday()]
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')} ({weekday_name})** - ğŸ“ {issue.description}")
            report.append("")
        
        # WFHå»ºè­°
        wfh_issues = [issue for issue in self.issues if issue.type == IssueType.WFH]
        if wfh_issues:
            report.append("## ğŸ  å»ºè­°ç”³è«‹WFHå‡çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(wfh_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ˜Š {issue.description}")
            report.append("")
        
        # çµ±è¨ˆæ‘˜è¦
        report.append("## ğŸ“Š çµ±è¨ˆæ‘˜è¦ï¼š\n")
        report.append(f"- ğŸ”„ å»ºè­°å¿˜åˆ·å¡å¤©æ•¸ï¼š{len(forget_punch_issues)} å¤©")
        report.append(f"- ğŸ˜° éœ€è¦è«‹é²åˆ°å¤©æ•¸ï¼š{len(late_issues)} å¤©")
        report.append(f"- ğŸ’ª åŠ ç­å¤©æ•¸ï¼š{len(overtime_issues)} å¤©")
        report.append(f"- ğŸ“ éœ€è¦è«‹å‡å¤©æ•¸ï¼š{len(weekday_leave_issues)} å¤©")
        report.append(f"- ğŸ  å»ºè­°WFHå¤©æ•¸ï¼š{len(wfh_issues)} å¤©")
        
        return "\n".join(report)
    
    def export_csv(self, filepath: str) -> None:
        """åŒ¯å‡ºCSVæ ¼å¼å ±å‘Š"""
        import csv
        
        # ä½¿ç”¨UTF-8-BOMç·¨ç¢¼å’Œåˆ†è™Ÿåˆ†éš”ç¬¦ä»¥ç¢ºä¿Mac Excelèƒ½æ­£ç¢ºé¡¯ç¤º
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f, delimiter=';')
            headers = ['æ—¥æœŸ', 'é¡å‹', 'æ™‚é•·(åˆ†é˜)', 'èªªæ˜', 'æ™‚æ®µ', 'è¨ˆç®—å¼']
            
            # å¢é‡æ¨¡å¼ä¸‹æ·»åŠ ç‹€æ…‹æ¬„ä½
            if self.incremental_mode:
                headers.append('ç‹€æ…‹')
            
            writer.writerow(headers)
            
            # å¦‚æœæ˜¯å¢é‡æ¨¡å¼ä¸”æ²’æœ‰å•é¡Œï¼Œè‡³å°‘æä¾›ä¸€è¡Œç‹€æ…‹è³‡è¨Š
            if self.incremental_mode and not self.issues and self.current_user:
                complete_days = self._identify_complete_work_days()
                if complete_days:
                    last_date = max(complete_days).strftime('%Y/%m/%d')
                    unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
                    # è®€å–ä¸Šæ¬¡åˆ†ææ™‚é–“
                    last_analysis_time = ""
                    if self.state_manager and self.current_user:
                        user_data = self.state_manager.state_data.get("users", {}).get(self.current_user, {})
                        ranges = user_data.get("processed_date_ranges", [])
                        if ranges:
                            last_analysis_time = max((r.get("last_analysis_time", "") for r in ranges), default="")
                    if not unprocessed_dates:  # æ²’æœ‰æ–°è³‡æ–™éœ€è¦è™•ç†
                        status_row = [
                            last_date,
                            "ç‹€æ…‹è³‡è¨Š",
                            0,
                            f"ğŸ“Š å¢é‡åˆ†æå®Œæˆï¼Œå·²è™•ç†è‡³ {last_date}ï¼Œå…± {len(complete_days)} å€‹å®Œæ•´å·¥ä½œæ—¥ | ä¸Šæ¬¡åˆ†ææ™‚é–“: {last_analysis_time}",
                            "",
                            "ä¸Šæ¬¡è™•ç†ç¯„åœå…§ç„¡æ–°å•é¡Œéœ€è¦ç”³è«‹",
                            "ç³»çµ±ç‹€æ…‹"
                        ]
                        writer.writerow(status_row)
            
            # å¯«å…¥å¯¦éš›å•é¡Œè¨˜éŒ„
            for issue in self.issues:
                row = [
                    issue.date.strftime('%Y/%m/%d'),
                    issue.type.value,
                    issue.duration_minutes,
                    issue.description,
                    issue.time_range,
                    issue.calculation
                ]
                
                # å¢é‡æ¨¡å¼ä¸‹æ·»åŠ ç‹€æ…‹è³‡è¨Š
                if self.incremental_mode:
                    status = "[NEW] æœ¬æ¬¡æ–°ç™¼ç¾" if issue.is_new else "å·²å­˜åœ¨"
                    row.append(status)
                
                writer.writerow(row)
    
    def export_excel(self, filepath: str) -> None:
        """åŒ¯å‡ºExcelæ ¼å¼å ±å‘Š"""
        try:
            from lib import excel_exporter
        except ImportError:
            logger.warning("âš ï¸  è­¦å‘Š: æœªå®‰è£ openpyxlï¼Œå›é€€ä½¿ç”¨CSVæ ¼å¼")
            logger.info("ğŸ’¡ å®‰è£æŒ‡ä»¤: pip install openpyxl")
            csv_filepath = filepath.replace('.xlsx', '.csv')
            self.export_csv(csv_filepath)
            logger.info("âœ… CSVå ±å‘Šå·²åŒ¯å‡º: %s", csv_filepath)
            return

        wb, ws, header_font, header_fill, border, center_alignment = (
            excel_exporter.init_workbook()
        )

        headers = ['æ—¥æœŸ', 'é¡å‹', 'æ™‚é•·(åˆ†é˜)', 'èªªæ˜', 'æ™‚æ®µ', 'è¨ˆç®—å¼']
        if self.incremental_mode:
            headers.append('ç‹€æ…‹')
        excel_exporter.write_headers(
            ws, headers, header_font, header_fill, border, center_alignment
        )

        data_start_row = 2
        if self.incremental_mode and not self.issues and self.current_user:
            complete_days = self._identify_complete_work_days()
            if complete_days:
                last_date = max(complete_days).strftime('%Y/%m/%d')
                unprocessed_dates = self._get_unprocessed_dates(
                    self.current_user, complete_days
                )
                # è®€å–ä¸Šæ¬¡åˆ†ææ™‚é–“
                last_analysis_time = ""
                if self.state_manager and self.current_user:
                    user_data = self.state_manager.state_data.get("users", {}).get(self.current_user, {})
                    ranges = user_data.get("processed_date_ranges", [])
                    if ranges:
                        last_analysis_time = max((r.get("last_analysis_time", "") for r in ranges), default="")
                if not unprocessed_dates:
                    data_start_row = excel_exporter.write_status_row(
                        ws, last_date, len(complete_days), last_analysis_time, border, center_alignment
                    )

        excel_exporter.write_issue_rows(
            ws,
            self.issues,
            data_start_row,
            self.incremental_mode,
            border,
            center_alignment,
        )

        excel_exporter.set_column_widths(ws, self.incremental_mode)
        excel_exporter.save_workbook(wb, filepath)

    def _backup_existing_file(self, filepath: str) -> None:
        """å‚™ä»½ç¾æœ‰æª”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œä½¿ç”¨æ™‚é–“æˆ³è¨˜ä½œç‚ºå¾Œç¶´
        Args:
            filepath: è¦æª¢æŸ¥ä¸¦å‚™ä»½çš„æª”æ¡ˆè·¯å¾‘
        """
        import os
        from datetime import datetime
        
        if os.path.exists(filepath):
            # ç”¢ç”Ÿæ™‚é–“æˆ³è¨˜å¾Œç¶´ (æ ¼å¼: YYYYMMDD_HHMMSS)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # åˆ†é›¢æª”åå’Œå‰¯æª”å
            base_name, ext = os.path.splitext(filepath)
            backup_filepath = f"{base_name}_{timestamp}{ext}"
            
            # å‚™ä»½æª”æ¡ˆ
            os.rename(filepath, backup_filepath)
            logger.info("ğŸ“¦ å‚™ä»½ç¾æœ‰æª”æ¡ˆ: %s", os.path.basename(backup_filepath))
    
    def export_report(self, filepath: str, format_type: str = 'excel') -> None:
        """çµ±ä¸€åŒ¯å‡ºä»‹é¢
        Args:
            filepath: æª”æ¡ˆè·¯å¾‘
            format_type: 'excel' æˆ– 'csv'
        """
        # åŒ¯å‡ºå‰å…ˆå‚™ä»½ç¾æœ‰æª”æ¡ˆ
        self._backup_existing_file(filepath)
        
        if format_type.lower() == 'csv':
            self.export_csv(filepath)
        else:
            self.export_excel(filepath)


def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='è€ƒå‹¤åˆ†æç³»çµ± - æ”¯æ´å¢é‡åˆ†æé¿å…é‡è¤‡è™•ç†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:
  # é è¨­å¢é‡åˆ†æï¼ˆæ¨è–¦ï¼‰
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt
  
  # å¼·åˆ¶å®Œæ•´é‡æ–°åˆ†æ
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt --full
  
  # æ¸…é™¤ä½¿ç”¨è€…ç‹€æ…‹å¾Œé‡æ–°åˆ†æ
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt --reset-state
  
  # æŒ‡å®šè¼¸å‡ºæ ¼å¼
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt csv
        """
    )
    
    parser.add_argument('filepath', help='è€ƒå‹¤æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('format', nargs='?', default='excel', 
                       choices=['excel', 'csv'], help='è¼¸å‡ºæ ¼å¼ (é è¨­: excel)')
    parser.add_argument('--incremental', '-i', action='store_true', default=True,
                       help='å•Ÿç”¨å¢é‡åˆ†ææ¨¡å¼ (é è¨­é–‹å•Ÿ)')
    parser.add_argument('--full', '-f', action='store_true',
                       help='å¼·åˆ¶å®Œæ•´é‡æ–°åˆ†æ')
    parser.add_argument('--reset-state', '-r', action='store_true',
                       help='æ¸…é™¤æŒ‡å®šä½¿ç”¨è€…çš„ç‹€æ…‹è¨˜éŒ„')
    
    args = parser.parse_args()
    
    filepath = args.filepath
    format_type = args.format
    
    # è™•ç†åˆ†ææ¨¡å¼
    incremental_mode = args.incremental and not args.full
    
    # è™•ç†ç‹€æ…‹é‡è¨­
    if args.reset_state:
        analyzer_temp = AttendanceAnalyzer()
        user_name, _, _ = analyzer_temp._extract_user_and_date_range_from_filename(filepath)
        if user_name:
            state_manager = AttendanceStateManager()
            if user_name in state_manager.state_data.get("users", {}):
                del state_manager.state_data["users"][user_name]
                state_manager.save_state()
                logger.info("ğŸ—‘ï¸  ç‹€æ…‹æª” 'attendance_state.json' å·²æ¸…é™¤ä½¿ç”¨è€… %s çš„è¨˜éŒ„ @ %s", user_name, datetime.now().isoformat())
            else:
                logger.info("â„¹ï¸  ä½¿ç”¨è€… %s æ²’æœ‰ç¾æœ‰ç‹€æ…‹éœ€è¦æ¸…é™¤", user_name)
        else:
            logger.warning("âš ï¸  ç„¡æ³•å¾æª”åè­˜åˆ¥ä½¿ç”¨è€…ï¼Œç„¡æ³•åŸ·è¡Œç‹€æ…‹é‡è¨­")
            sys.exit(1)
    
    try:
        analyzer = AttendanceAnalyzer()
        
        # é¡¯ç¤ºåˆ†ææ¨¡å¼
        if incremental_mode:
            logger.info("ğŸ“‚ æ­£åœ¨è§£æè€ƒå‹¤æª”æ¡ˆ... (å¢é‡åˆ†ææ¨¡å¼)")
        else:
            logger.info("ğŸ“‚ æ­£åœ¨è§£æè€ƒå‹¤æª”æ¡ˆ... (å®Œæ•´åˆ†ææ¨¡å¼)")
            
        analyzer.parse_attendance_file(filepath, incremental=incremental_mode)
        
        logger.info("ğŸ“ æ­£åœ¨åˆ†çµ„è¨˜éŒ„...")
        analyzer.group_records_by_day()
        
        logger.info("ğŸ” æ­£åœ¨åˆ†æè€ƒå‹¤...")
        analyzer.analyze_attendance()
        
        logger.info("ğŸ“Š æ­£åœ¨ç”Ÿæˆå ±å‘Š...")
        report = analyzer.generate_report()
        
        # å¼·åˆ¶é¡¯ç¤ºå®Œæ•´å ±å‘Šï¼Œæ¯è¡Œå–®ç¨è¼¸å‡º
        logger.info("\n")
        for line in report.split('\n'):
            logger.info(line)
        
        # æ ¹æ“šæŒ‡å®šæ ¼å¼åŒ¯å‡ºï¼ˆä½¿ç”¨çµ±ä¸€ä»‹é¢ï¼ŒåŒ…å«è‡ªå‹•å‚™ä»½ï¼‰
        if format_type.lower() == 'csv':
            output_filepath = filepath.replace('.txt', '_analysis.csv')
            analyzer.export_report(output_filepath, 'csv')
            logger.info("âœ… CSVå ±å‘Šå·²åŒ¯å‡º: %s", output_filepath)
        else:
            output_filepath = filepath.replace('.txt', '_analysis.xlsx')
            analyzer.export_report(output_filepath, 'excel')
            logger.info("âœ… Excelå ±å‘Šå·²åŒ¯å‡º: %s", output_filepath)
        
        # åŒæ™‚ä¿ç•™CSVæ ¼å¼ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
        if format_type.lower() == 'excel':
            csv_filepath = filepath.replace('.txt', '_analysis.csv')
            analyzer.export_report(csv_filepath, 'csv')
            logger.info("ğŸ“ åŒæ™‚åŒ¯å‡ºCSVæ ¼å¼: %s", csv_filepath)
        
    except Exception as e:
        logger.error("âŒ éŒ¯èª¤: %s", e)
        sys.exit(1)


if __name__ == "__main__":
    main()
