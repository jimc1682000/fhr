#!/usr/bin/env python3
"""
è€ƒå‹¤åˆ†æç³»çµ±
ç”¨æ–¼åˆ†æè€ƒå‹¤è¨˜éŒ„ä¸¦è¨ˆç®—é²åˆ°/åŠ ç­æ™‚æ•¸
"""

import re
import sys
import json
import os
import logging
import time  # unused; kept previously, now removed for clarity
from collections import defaultdict
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
from urllib.parse import urlparse


logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


class AttendanceType(Enum):
    CHECKIN = "ä¸Šç­"
    CHECKOUT = "ä¸‹ç­"


class IssueType(Enum):
    LATE = "é²åˆ°"
    FORGET_PUNCH = "å¿˜åˆ·å¡"
    OVERTIME = "åŠ ç­"
    WFH = "WFHå‡"
    WEEKDAY_LEAVE = "è«‹å‡"


@dataclass
class AttendanceRecord:
    date: datetime
    scheduled_time: Optional[datetime]
    actual_time: Optional[datetime]
    type: AttendanceType
    card_number: str
    source: str
    status: str
    processed: str
    operation: str
    note: str


@dataclass
class WorkDay:
    date: datetime
    checkin_record: Optional[AttendanceRecord]
    checkout_record: Optional[AttendanceRecord]
    is_friday: bool
    is_holiday: bool = False


@dataclass
class Issue:
    date: datetime
    type: IssueType
    duration_minutes: int
    description: str
    time_range: str = ""
    calculation: str = ""
    is_new: bool = True  # æ¨™ç¤ºæ˜¯å¦ç‚ºæœ¬æ¬¡æ–°ç™¼ç¾çš„å•é¡Œ


    # AttendanceStateManager å·²æŠ½é›¢è‡³ lib.state


class AttendanceAnalyzer:
    """è€ƒå‹¤åˆ†æå™¨"""
    
    # å…¬å¸è¦å‰‡å¸¸æ•¸ï¼ˆå¯ç”±è¨­å®šæª”è¦†è“‹ï¼‰
    EARLIEST_CHECKIN = "08:30"
    LATEST_CHECKIN = "10:30"
    LUNCH_START = "12:30"
    LUNCH_END = "13:30"
    WORK_HOURS = 8
    LUNCH_HOURS = 1
    MIN_OVERTIME_MINUTES = 60
    OVERTIME_INCREMENT_MINUTES = 60  # æ”¹ç‚ºæ¯å°æ™‚ä¸€å€‹å€é–“
    FORGET_PUNCH_ALLOWANCE_PER_MONTH = 2  # æ¯æœˆå¿˜åˆ·å¡æ¬¡æ•¸
    FORGET_PUNCH_MAX_MINUTES = 60  # å¿˜åˆ·å¡æœ€å¤šå¯ç”¨æ–¼60åˆ†é˜å…§çš„é²åˆ°

    def __init__(self, config_path: str = "config.json"):
        self._load_config(config_path)
        self.records: List[AttendanceRecord] = []
        self.workdays: List[WorkDay] = []
        self.issues: List[Issue] = []
        self.holidays: set = set()  # å­˜æ”¾åœ‹å®šå‡æ—¥æ—¥æœŸ
        self.forget_punch_usage: Dict[str, int] = defaultdict(int)  # è¿½è¹¤æ¯æœˆå¿˜åˆ·å¡ä½¿ç”¨æ¬¡æ•¸ {å¹´æœˆ: æ¬¡æ•¸}
        self.loaded_holiday_years: set = set()  # è¿½è¹¤å·²è¼‰å…¥å‡æ—¥çš„å¹´ä»½
        self.state_manager: Optional[AttendanceStateManager] = None
        self.current_user: Optional[str] = None
        self.incremental_mode: bool = True

    def _load_config(self, config_path: str) -> None:
        """è¼‰å…¥è¨­å®šæª”ä»¥è¦†è“‹é è¨­å…¬å¸è¦å‰‡"""
        if not os.path.exists(config_path):
            logger.info("æ‰¾ä¸åˆ°è¨­å®šæª” %sï¼Œä½¿ç”¨é è¨­å€¼", config_path)
            return
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for key, value in data.items():
                if hasattr(self, key):
                    setattr(self, key, value)
        except (OSError, json.JSONDecodeError) as e:
            logger.warning("ç„¡æ³•è®€å–è¨­å®šæª” %s: %s", config_path, e)
    
    
    def _identify_complete_work_days(self) -> List[datetime]:
        """è­˜åˆ¥å®Œæ•´çš„å·¥ä½œæ—¥ï¼ˆæœ‰ä¸Šç­å’Œä¸‹ç­è¨˜éŒ„çš„æ—¥æœŸï¼‰
        Returns:
            å®Œæ•´å·¥ä½œæ—¥çš„æ—¥æœŸæ¸…å–®
        """
        complete_days = []
        daily_records = defaultdict(lambda: {'checkin': False, 'checkout': False})

        # æŒ‰æ—¥æœŸåˆ†çµ„è¨˜éŒ„
        for record in self.records:
            if not record.date:
                continue

            if record.type == AttendanceType.CHECKIN:
                daily_records[record.date]['checkin'] = True
            else:
                daily_records[record.date]['checkout'] = True
        
        # æ‰¾å‡ºæœ‰ä¸Šç­å’Œä¸‹ç­è¨˜éŒ„çš„å®Œæ•´å·¥ä½œæ—¥
        for date, records in daily_records.items():
            if records['checkin'] and records['checkout']:
                complete_days.append(datetime.combine(date, datetime.min.time()))
        
        return sorted(complete_days)
    
    def _get_unprocessed_dates(self, user_name: str, complete_days: List[datetime]) -> List[datetime]:
        """å–å¾—éœ€è¦è™•ç†çš„æ–°æ—¥æœŸï¼ˆæ’é™¤å·²è™•ç†çš„é‡ç–Šæ—¥æœŸï¼‰
        Args:
            user_name: ä½¿ç”¨è€…å§“å
            complete_days: å®Œæ•´å·¥ä½œæ—¥æ¸…å–®
        Returns:
            éœ€è¦è™•ç†çš„æ—¥æœŸæ¸…å–®
        """
        if not self.state_manager or not self.incremental_mode:
            return complete_days
        
        processed_ranges = self.state_manager.get_user_processed_ranges(user_name)
        unprocessed_dates = []
        
        for day in complete_days:
            day_str = day.strftime("%Y-%m-%d")
            is_processed = False
            
            # æª¢æŸ¥é€™å€‹æ—¥æœŸæ˜¯å¦å·²åœ¨ä¹‹å‰è™•ç†éçš„ç¯„åœå…§
            for range_info in processed_ranges:
                if range_info["start_date"] <= day_str <= range_info["end_date"]:
                    is_processed = True
                    break
            
            if not is_processed:
                unprocessed_dates.append(day)
        
        return unprocessed_dates
    
    def _load_previous_forget_punch_usage(self, user_name: str) -> None:
        """è¼‰å…¥ä¹‹å‰çš„å¿˜åˆ·å¡ä½¿ç”¨çµ±è¨ˆ"""
        if not self.state_manager or not self.incremental_mode:
            return
        
        # æ¸…ç©ºç¾æœ‰çµ±è¨ˆ
        self.forget_punch_usage = defaultdict(int)
        
        # å¾ç‹€æ…‹ç®¡ç†å™¨è¼‰å…¥
        user_data = self.state_manager.state_data.get("users", {}).get(user_name, {})
        previous_usage = user_data.get("forget_punch_usage", {})
        
        # è¤‡è£½åˆ°æœ¬åœ°çµ±è¨ˆ
        self.forget_punch_usage.update(previous_usage)
    
    def _get_years_from_records(self) -> set:
        """å¾å‡ºå‹¤è¨˜éŒ„ä¸­æå–å¹´ä»½"""
        years = set()
        for record in self.records:
            if record.date:
                years.add(record.date.year)
        return years
    
    def _load_taiwan_holidays(self, years: set = None) -> None:
        """è¼‰å…¥å°ç£åœ‹å®šå‡æ—¥è³‡æ–™
        Args:
            years: éœ€è¦è¼‰å…¥çš„å¹´ä»½é›†åˆï¼ŒNoneè¡¨ç¤ºåªè¼‰å…¥ç•¶å¹´(2025)
        """
        if years is None:
            years = {2025}  # é è¨­è¼‰å…¥ç•¶å¹´
        
        for year in years:
            if year not in self.loaded_holiday_years:
                from lib.holidays import HolidayService
                logger.info("è³‡è¨Š: å‹•æ…‹è¼‰å…¥ %d å¹´åœ‹å®šå‡æ—¥...", year)
                service = HolidayService()
                self.holidays |= service.load_year(year)
                self.loaded_holiday_years.add(year)
    
    def _try_load_from_gov_api(self, year: int) -> bool:
        # å‘å¾Œç›¸å®¹ï¼šä¿ç•™æœ¬æ¨¡çµ„å…§çš„ scheme æª¢æŸ¥ï¼ˆä¾›å–®å…ƒæ¸¬è©¦ patchï¼‰
        url = "https://data.gov.tw/api/v1/rest/datastore_search?resource_id=W2&filters={\"date\":\"%s\"}" % year
        parsed = urlparse(url)
        if parsed.scheme not in {"http", "https"}:
            logger.warning("ä¸æ”¯æ´çš„ URL scheme: %s", parsed.scheme)
            return False
        from lib.holidays import TaiwanGovOpenDataProvider
        out = TaiwanGovOpenDataProvider().load(year)
        if out:
            self.holidays |= out
            return True
        return False
    
    def parse_attendance_file(self, filepath: str, incremental: bool = True) -> None:
        """è§£æè€ƒå‹¤è³‡æ–™æª”æ¡ˆä¸¦åˆå§‹åŒ–å¢é‡è™•ç†
        Args:
            filepath: æª”æ¡ˆè·¯å¾‘
            incremental: æ˜¯å¦å•Ÿç”¨å¢é‡åˆ†æ
        """
        self.incremental_mode = incremental
        
        # åˆå§‹åŒ–ç‹€æ…‹ç®¡ç†å™¨
        if self.incremental_mode:
            from lib.state import AttendanceStateManager
            self.state_manager = AttendanceStateManager()
            
            # è§£ææª”åå–å¾—ä½¿ç”¨è€…è³‡è¨Š
            from lib.filename import parse_range_and_user
            user_name, start_date, end_date = parse_range_and_user(filepath)
            if user_name:
                self.current_user = user_name
                logger.info("ğŸ“‹ è­˜åˆ¥ä½¿ç”¨è€…: %s", user_name)
                logger.info("ğŸ“… æª”æ¡ˆæ¶µè“‹æœŸé–“: %s è‡³ %s", start_date, end_date)
                
                # æª¢æŸ¥é‡ç–Šæ—¥æœŸ
                if start_date and end_date:
                    overlaps = self.state_manager.detect_date_overlap(user_name, start_date, end_date)
                    if overlaps:
                        logger.warning("âš ï¸  ç™¼ç¾é‡ç–Šæ—¥æœŸç¯„åœ: %s", overlaps)
                        logger.warning("å°‡ä»¥èˆŠè³‡æ–™ç‚ºä¸»ï¼Œåƒ…è™•ç†æ–°æ—¥æœŸ")
                
                # è¼‰å…¥ä¹‹å‰çš„å¿˜åˆ·å¡ä½¿ç”¨çµ±è¨ˆ
                self._load_previous_forget_punch_usage(user_name)
            else:
                logger.warning("âš ï¸  ç„¡æ³•å¾æª”åè­˜åˆ¥ä½¿ç”¨è€…ï¼Œå°‡ä½¿ç”¨å®Œæ•´åˆ†ææ¨¡å¼")
                self.incremental_mode = False
        
        # è§£ææª”æ¡ˆå…§å®¹
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        for line_num, line in enumerate(lines, 1):
            if line_num == 1:  # è·³éè¡¨é ­
                continue
                
            line = line.strip()
            if not line:
                continue
                
            try:
                record = self._parse_attendance_line(line)
                if record:
                    self.records.append(record)
            except (ValueError, IndexError) as e:
                logger.warning("ç¬¬%dè¡Œè§£æå¤±æ•—: %s", line_num, e)
    
    def _parse_attendance_line(self, line: str) -> Optional[AttendanceRecord]:
        """è§£æå–®è¡Œè€ƒå‹¤è¨˜éŒ„ï¼ˆå§”æ´¾è‡³ lib.parserï¼‰"""
        from lib import parser as p
        parsed = p.parse_line(line)
        if not parsed:
            return None
        scheduled_time, actual_time, type_str, card_num, source, status, processed, operation, note = parsed
        attendance_type = AttendanceType.CHECKIN if type_str == "ä¸Šç­" else AttendanceType.CHECKOUT
        return AttendanceRecord(
            date=scheduled_time.date() if scheduled_time else None,
            scheduled_time=scheduled_time,
            actual_time=actual_time,
            type=attendance_type,
            card_number=card_num,
            source=source,
            status=status,
            processed=processed,
            operation=operation,
            note=note,
        )
    
    def group_records_by_day(self) -> None:
        """å°‡è¨˜éŒ„æŒ‰æ—¥æœŸåˆ†çµ„"""
        # åœ¨åˆ†çµ„å‰ï¼Œå…ˆè¼‰å…¥å‡ºå‹¤è³‡æ–™ä¸­æ¶‰åŠçš„å¹´ä»½å‡æ—¥
        years_in_data = self._get_years_from_records()
        if years_in_data:
            self._load_taiwan_holidays(years_in_data)
        
        from lib.grouping import group_daily
        daily_records = group_daily(self.records)
        
        for date, records in daily_records.items():
            workday = WorkDay(
                date=datetime.combine(date, datetime.min.time()),
                checkin_record=records['checkin'],
                checkout_record=records['checkout'],
                is_friday=(date.weekday() == 4),  # é€±äº”æ˜¯4
                is_holiday=(date in self.holidays)  # æª¢æŸ¥æ˜¯å¦ç‚ºåœ‹å®šå‡æ—¥
            )
            self.workdays.append(workday)
        
        self.workdays.sort(key=lambda x: x.date)
    
    def analyze_attendance(self) -> None:
        """åˆ†æè€ƒå‹¤è¨˜éŒ„ï¼ˆæ”¯æ´å¢é‡åˆ†æï¼‰"""
        self.issues = []
        
        # å¢é‡åˆ†ææ¨¡å¼ï¼šåªåˆ†ææ–°çš„å®Œæ•´å·¥ä½œæ—¥
        if self.incremental_mode and self.current_user:
            complete_days = self._identify_complete_work_days()
            unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
            
            if unprocessed_dates:
                logger.info("ğŸ”„ å¢é‡åˆ†æ: ç™¼ç¾ %d å€‹æ–°çš„å®Œæ•´å·¥ä½œæ—¥éœ€è¦è™•ç†", len(unprocessed_dates))
                logger.info("ğŸ“Š è·³éå·²è™•ç†çš„å·¥ä½œæ—¥: %d å€‹", len(complete_days) - len(unprocessed_dates))
                
                # åªåˆ†ææœªè™•ç†çš„å·¥ä½œæ—¥
                unprocessed_date_set = {d.date() for d in unprocessed_dates}
                workdays_to_analyze = [wd for wd in self.workdays if wd.date.date() in unprocessed_date_set]
            else:
                logger.info("âœ… å¢é‡åˆ†æ: æ²’æœ‰æ–°çš„å·¥ä½œæ—¥éœ€è¦è™•ç†")
                workdays_to_analyze = []
        else:
            # å®Œæ•´åˆ†ææ¨¡å¼ï¼šåˆ†ææ‰€æœ‰å·¥ä½œæ—¥
            workdays_to_analyze = self.workdays
        
        from lib.policy import Rules, is_full_day_absent, calculate_late_minutes, calculate_overtime_minutes
        rules = Rules(
            earliest_checkin=self.EARLIEST_CHECKIN,
            latest_checkin=self.LATEST_CHECKIN,
            lunch_start=self.LUNCH_START,
            lunch_end=self.LUNCH_END,
            work_hours=self.WORK_HOURS,
            lunch_hours=self.LUNCH_HOURS,
            min_overtime_minutes=self.MIN_OVERTIME_MINUTES,
            overtime_increment_minutes=self.OVERTIME_INCREMENT_MINUTES,
            forget_punch_allowance_per_month=self.FORGET_PUNCH_ALLOWANCE_PER_MONTH,
            forget_punch_max_minutes=self.FORGET_PUNCH_MAX_MINUTES,
        )

        for workday in workdays_to_analyze:
            # æª¢æŸ¥æ˜¯å¦æ•´å¤©æ²’æœ‰æ‰“å¡è¨˜éŒ„ï¼ˆæ› è·ï¼‰
            if is_full_day_absent(workday):
                if workday.is_friday and not workday.is_holiday:
                    # é€±äº”ä¸”éåœ‹å®šå‡æ—¥å»ºè­°WFHå‡
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.WFH,
                        duration_minutes=9 * 60,  # 9å°æ™‚
                        description="å»ºè­°ç”³è«‹æ•´å¤©WFHå‡ ğŸ ğŸ’»"
                    ))
                elif not workday.is_holiday:
                    # éåœ‹å®šå‡æ—¥çš„é€±ä¸€åˆ°é€±å››å»ºè­°è«‹å‡
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.WEEKDAY_LEAVE,
                        duration_minutes=8 * 60,  # 8å°æ™‚
                        description="æ•´å¤©æ²’é€²å…¬å¸ï¼Œå»ºè­°è«‹å‡ ğŸ“ğŸ "
                    ))
                # å¦‚æœæ˜¯åœ‹å®šå‡æ—¥ï¼Œå‰‡ä¸éœ€è¦ä»»ä½•ç”³è«‹å»ºè­°
                continue
            
            if workday.is_friday:
                # é€±äº”å·²è™•ç†ï¼Œè·³éåˆ†æ
                continue
            
            # åˆ†æé²åˆ°
            late_minutes, late_time_range, late_calculation = calculate_late_minutes(workday, rules)
            if late_minutes > 0:
                # æª¢æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨å¿˜åˆ·å¡
                month_key = workday.date.strftime('%Y-%m')
                can_use_forget_punch = (
                    late_minutes <= self.FORGET_PUNCH_MAX_MINUTES and
                    self.forget_punch_usage[month_key] < self.FORGET_PUNCH_ALLOWANCE_PER_MONTH
                )
                
                if can_use_forget_punch:
                    # ä½¿ç”¨å¿˜åˆ·å¡
                    self.forget_punch_usage[month_key] += 1
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.FORGET_PUNCH,
                        duration_minutes=0,  # å¿˜åˆ·å¡ä¸éœ€è¦è«‹å‡
                        description=f"é²åˆ°{late_minutes}åˆ†é˜ï¼Œå»ºè­°ä½¿ç”¨å¿˜åˆ·å¡ ğŸ”„âœ…",
                        time_range=late_time_range,
                        calculation=f"{late_calculation} (ä½¿ç”¨å¿˜åˆ·å¡ï¼Œæœ¬æœˆå‰©é¤˜: {self.FORGET_PUNCH_ALLOWANCE_PER_MONTH - self.forget_punch_usage[month_key]}æ¬¡)"
                    ))
                else:
                    # éœ€è¦è«‹é²åˆ°å‡
                    reason = "è¶…é1å°æ™‚" if late_minutes > self.FORGET_PUNCH_MAX_MINUTES else f"æœ¬æœˆå¿˜åˆ·å¡é¡åº¦å·²ç”¨å®Œ"
                    self.issues.append(Issue(
                        date=workday.date,
                        type=IssueType.LATE,
                        duration_minutes=late_minutes,
                        description=f"é²åˆ°{late_minutes}åˆ†é˜ â±ï¸ ({reason})",
                        time_range=late_time_range,
                        calculation=late_calculation
                    ))
            
            # åˆ†æåŠ ç­
            actual_overtime, applicable_overtime, overtime_time_range, overtime_calculation = calculate_overtime_minutes(workday, rules)
            if applicable_overtime >= self.MIN_OVERTIME_MINUTES:
                self.issues.append(Issue(
                    date=workday.date,
                    type=IssueType.OVERTIME,
                    duration_minutes=applicable_overtime,
                    description=f"åŠ ç­{applicable_overtime // 60}å°æ™‚{applicable_overtime % 60}åˆ†é˜ ğŸ’¼",
                    time_range=overtime_time_range,
                    calculation=overtime_calculation
                ))
        
        # å¢é‡åˆ†ææ¨¡å¼ï¼šæ›´æ–°ç‹€æ…‹
        if self.incremental_mode and self.current_user and workdays_to_analyze:
            self._update_processing_state()
    
    def _update_processing_state(self) -> None:
        """æ›´æ–°è™•ç†ç‹€æ…‹åˆ°ç‹€æ…‹æª”æ¡ˆ"""
        if not self.state_manager or not self.current_user:
            return
        
        # è¨ˆç®—è™•ç†ç¯„åœ
        complete_days = self._identify_complete_work_days()
        if not complete_days:
            return
        
        start_date = min(complete_days).strftime("%Y-%m-%d")
        end_date = max(complete_days).strftime("%Y-%m-%d")
        
        # æ§‹å»ºç¯„åœè³‡è¨Š
        range_info = {
            "start_date": start_date,
            "end_date": end_date,
            "source_file": os.path.basename(sys.argv[1]) if len(sys.argv) > 1 else "unknown",
            "last_analysis_time": datetime.now().isoformat()
        }
        
        # æ›´æ–°ç‹€æ…‹
        self.state_manager.update_user_state(
            self.current_user,
            range_info,
            self.forget_punch_usage
        )
        
        # å„²å­˜ç‹€æ…‹æª”æ¡ˆ
        self.state_manager.save_state()
        logger.info("ğŸ’¾ å·²æ›´æ–°è™•ç†ç‹€æ…‹: %s è‡³ %s", start_date, end_date)
    
    
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå ±å‘Šï¼ˆæ”¯æ´å¢é‡åˆ†æè³‡è¨Šé¡¯ç¤ºï¼‰"""
        report = []
        report.append("# ğŸ¯ è€ƒå‹¤åˆ†æå ±å‘Š âœ¨\n")
        
        # é¡¯ç¤ºå¢é‡åˆ†æè³‡è¨Š
        if self.incremental_mode and self.current_user:
            complete_days = self._identify_complete_work_days()
            unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
            from lib.report import build_incremental_lines
            report.extend(
                build_incremental_lines(
                    self.current_user,
                    len(complete_days),
                    len(unprocessed_dates),
                    [d.strftime('%Y/%m/%d') for d in unprocessed_dates],
                )
            )
        
        # å¿˜åˆ·å¡å»ºè­°
        forget_punch_issues = [issue for issue in self.issues if issue.type == IssueType.FORGET_PUNCH]
        from lib.report import build_issue_section, build_summary
        report.extend(
            build_issue_section("## ğŸ”„ å»ºè­°ä½¿ç”¨å¿˜åˆ·å¡çš„æ—¥æœŸï¼š", "ğŸ”„", forget_punch_issues)
        )
        
        # é²åˆ°çµ±è¨ˆ
        late_issues = [issue for issue in self.issues if issue.type == IssueType.LATE]
        report.extend(
            build_issue_section("## ğŸ˜° éœ€è¦è«‹é²åˆ°çš„æ—¥æœŸï¼š", "ğŸ˜…", late_issues)
        )
        
        # åŠ ç­çµ±è¨ˆ
        overtime_issues = [issue for issue in self.issues if issue.type == IssueType.OVERTIME]
        report.extend(
            build_issue_section("## ğŸ’ª éœ€è¦è«‹åŠ ç­çš„æ—¥æœŸï¼š", "ğŸ”¥", overtime_issues)
        )
        
        # é€±ä¸€åˆ°é€±å››è«‹å‡å»ºè­°
        weekday_leave_issues = [issue for issue in self.issues if issue.type == IssueType.WEEKDAY_LEAVE]
        if weekday_leave_issues:
            report.append("## ğŸ“ éœ€è¦è«‹å‡çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(weekday_leave_issues, 1):
                weekday_name = ['é€±ä¸€', 'é€±äºŒ', 'é€±ä¸‰', 'é€±å››', 'é€±äº”', 'é€±å…­', 'é€±æ—¥'][issue.date.weekday()]
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')} ({weekday_name})** - ğŸ“ {issue.description}")
            report.append("")
        
        # WFHå»ºè­°
        wfh_issues = [issue for issue in self.issues if issue.type == IssueType.WFH]
        if wfh_issues:
            report.append("## ğŸ  å»ºè­°ç”³è«‹WFHå‡çš„æ—¥æœŸï¼š\n")
            for i, issue in enumerate(wfh_issues, 1):
                report.append(f"{i}. **{issue.date.strftime('%Y/%m/%d')}** - ğŸ˜Š {issue.description}")
            report.append("")
        
        # çµ±è¨ˆæ‘˜è¦
        report.extend(
            build_summary(
                len(forget_punch_issues),
                len(late_issues),
                len(overtime_issues),
                len(weekday_leave_issues),
                len(wfh_issues),
            )
        )
        
        return "\n".join(report)
    
    def export_csv(self, filepath: str) -> None:
        """åŒ¯å‡ºCSVæ ¼å¼å ±å‘Šï¼ˆå§”æ´¾è‡³ lib.csv_exporterï¼‰"""
        from lib import csv_exporter

        status_tuple = None
        if self.incremental_mode and not self.issues and self.current_user:
            complete_days = self._identify_complete_work_days()
            if complete_days:
                last_date = max(complete_days).strftime('%Y/%m/%d')
                unprocessed_dates = self._get_unprocessed_dates(self.current_user, complete_days)
                # è®€å–ä¸Šæ¬¡åˆ†ææ™‚é–“
                last_analysis_time = ""
                if self.state_manager and self.current_user:
                    user_data = self.state_manager.state_data.get("users", {}).get(self.current_user, {})
                    ranges = user_data.get("processed_date_ranges", [])
                    if ranges:
                        last_analysis_time = max((r.get("last_analysis_time", "") for r in ranges), default="")
                if not unprocessed_dates:
                    status_tuple = (last_date, len(complete_days), last_analysis_time)

        csv_exporter.save_csv(filepath, self.issues, self.incremental_mode, status_tuple)
    
    def export_excel(self, filepath: str) -> None:
        """åŒ¯å‡ºExcelæ ¼å¼å ±å‘Š"""
        try:
            from lib import excel_exporter
        except ImportError:
            logger.warning("âš ï¸  è­¦å‘Š: æœªå®‰è£ openpyxlï¼Œå›é€€ä½¿ç”¨CSVæ ¼å¼")
            logger.info("ğŸ’¡ å®‰è£æŒ‡ä»¤: pip install openpyxl")
            csv_filepath = filepath.replace('.xlsx', '.csv')
            self.export_csv(csv_filepath)
            logger.info("âœ… CSVå ±å‘Šå·²åŒ¯å‡º: %s", csv_filepath)
            return

        wb, ws, header_font, header_fill, border, center_alignment = (
            excel_exporter.init_workbook()
        )

        headers = ['æ—¥æœŸ', 'é¡å‹', 'æ™‚é•·(åˆ†é˜)', 'èªªæ˜', 'æ™‚æ®µ', 'è¨ˆç®—å¼']
        if self.incremental_mode:
            headers.append('ç‹€æ…‹')
        excel_exporter.write_headers(
            ws, headers, header_font, header_fill, border, center_alignment
        )

        data_start_row = 2
        if self.incremental_mode and not self.issues and self.current_user:
            complete_days = self._identify_complete_work_days()
            if complete_days:
                last_date = max(complete_days).strftime('%Y/%m/%d')
                unprocessed_dates = self._get_unprocessed_dates(
                    self.current_user, complete_days
                )
                # è®€å–ä¸Šæ¬¡åˆ†ææ™‚é–“
                last_analysis_time = ""
                if self.state_manager and self.current_user:
                    user_data = self.state_manager.state_data.get("users", {}).get(self.current_user, {})
                    ranges = user_data.get("processed_date_ranges", [])
                    if ranges:
                        last_analysis_time = max((r.get("last_analysis_time", "") for r in ranges), default="")
                if not unprocessed_dates:
                    data_start_row = excel_exporter.write_status_row(
                        ws, last_date, len(complete_days), last_analysis_time, border, center_alignment
                    )

        excel_exporter.write_issue_rows(
            ws,
            self.issues,
            data_start_row,
            self.incremental_mode,
            border,
            center_alignment,
        )

        excel_exporter.set_column_widths(ws, self.incremental_mode)
        excel_exporter.save_workbook(wb, filepath)

    def export_report(self, filepath: str, format_type: str = 'excel') -> None:
        """çµ±ä¸€åŒ¯å‡ºä»‹é¢
        Args:
            filepath: æª”æ¡ˆè·¯å¾‘
            format_type: 'excel' æˆ– 'csv'
        """
        # åŒ¯å‡ºå‰å…ˆå‚™ä»½ç¾æœ‰æª”æ¡ˆï¼ˆç§»è‡³ lib.backupï¼‰
        from lib.backup import backup_with_timestamp
        backup_path = backup_with_timestamp(filepath)
        if backup_path:
            logger.info("ğŸ“¦ å‚™ä»½ç¾æœ‰æª”æ¡ˆ: %s", os.path.basename(backup_path))
        
        if format_type.lower() == 'csv':
            self.export_csv(filepath)
        else:
            self.export_excel(filepath)


def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='è€ƒå‹¤åˆ†æç³»çµ± - æ”¯æ´å¢é‡åˆ†æé¿å…é‡è¤‡è™•ç†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:
  # é è¨­å¢é‡åˆ†æï¼ˆæ¨è–¦ï¼‰
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt
  
  # å¼·åˆ¶å®Œæ•´é‡æ–°åˆ†æ
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt --full
  
  # æ¸…é™¤ä½¿ç”¨è€…ç‹€æ…‹å¾Œé‡æ–°åˆ†æ
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt --reset-state
  
  # æŒ‡å®šè¼¸å‡ºæ ¼å¼
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt csv
        """
    )
    
    parser.add_argument('filepath', help='è€ƒå‹¤æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('format', nargs='?', default='excel', 
                       choices=['excel', 'csv'], help='è¼¸å‡ºæ ¼å¼ (é è¨­: excel)')
    parser.add_argument('--incremental', '-i', action='store_true', default=True,
                       help='å•Ÿç”¨å¢é‡åˆ†ææ¨¡å¼ (é è¨­é–‹å•Ÿ)')
    parser.add_argument('--full', '-f', action='store_true',
                       help='å¼·åˆ¶å®Œæ•´é‡æ–°åˆ†æ')
    parser.add_argument('--reset-state', '-r', action='store_true',
                       help='æ¸…é™¤æŒ‡å®šä½¿ç”¨è€…çš„ç‹€æ…‹è¨˜éŒ„')
    
    args = parser.parse_args()
    
    filepath = args.filepath
    format_type = args.format
    
    # è™•ç†åˆ†ææ¨¡å¼
    incremental_mode = args.incremental and not args.full
    
    # è™•ç†ç‹€æ…‹é‡è¨­
    if args.reset_state:
        analyzer_temp = AttendanceAnalyzer()
        from lib.filename import parse_range_and_user
        from lib.state import AttendanceStateManager
        user_name, _, _ = parse_range_and_user(filepath)
        if user_name:
            state_manager = AttendanceStateManager()
            if user_name in state_manager.state_data.get("users", {}):
                del state_manager.state_data["users"][user_name]
                state_manager.save_state()
                logger.info("ğŸ—‘ï¸  ç‹€æ…‹æª” 'attendance_state.json' å·²æ¸…é™¤ä½¿ç”¨è€… %s çš„è¨˜éŒ„ @ %s", user_name, datetime.now().isoformat())
            else:
                logger.info("â„¹ï¸  ä½¿ç”¨è€… %s æ²’æœ‰ç¾æœ‰ç‹€æ…‹éœ€è¦æ¸…é™¤", user_name)
        else:
            logger.warning("âš ï¸  ç„¡æ³•å¾æª”åè­˜åˆ¥ä½¿ç”¨è€…ï¼Œç„¡æ³•åŸ·è¡Œç‹€æ…‹é‡è¨­")
            sys.exit(1)
    
    try:
        analyzer = AttendanceAnalyzer()
        
        # é¡¯ç¤ºåˆ†ææ¨¡å¼
        if incremental_mode:
            logger.info("ğŸ“‚ æ­£åœ¨è§£æè€ƒå‹¤æª”æ¡ˆ... (å¢é‡åˆ†ææ¨¡å¼)")
        else:
            logger.info("ğŸ“‚ æ­£åœ¨è§£æè€ƒå‹¤æª”æ¡ˆ... (å®Œæ•´åˆ†ææ¨¡å¼)")
            
        analyzer.parse_attendance_file(filepath, incremental=incremental_mode)
        
        logger.info("ğŸ“ æ­£åœ¨åˆ†çµ„è¨˜éŒ„...")
        analyzer.group_records_by_day()
        
        logger.info("ğŸ” æ­£åœ¨åˆ†æè€ƒå‹¤...")
        analyzer.analyze_attendance()
        
        logger.info("ğŸ“Š æ­£åœ¨ç”Ÿæˆå ±å‘Š...")
        report = analyzer.generate_report()
        
        # å¼·åˆ¶é¡¯ç¤ºå®Œæ•´å ±å‘Šï¼Œæ¯è¡Œå–®ç¨è¼¸å‡º
        logger.info("\n")
        for line in report.split('\n'):
            logger.info(line)
        
        # æ ¹æ“šæŒ‡å®šæ ¼å¼åŒ¯å‡ºï¼ˆä½¿ç”¨çµ±ä¸€ä»‹é¢ï¼ŒåŒ…å«è‡ªå‹•å‚™ä»½ï¼‰
        if format_type.lower() == 'csv':
            output_filepath = filepath.replace('.txt', '_analysis.csv')
            analyzer.export_report(output_filepath, 'csv')
            logger.info("âœ… CSVå ±å‘Šå·²åŒ¯å‡º: %s", output_filepath)
        else:
            output_filepath = filepath.replace('.txt', '_analysis.xlsx')
            analyzer.export_report(output_filepath, 'excel')
            logger.info("âœ… Excelå ±å‘Šå·²åŒ¯å‡º: %s", output_filepath)
        
        # åŒæ™‚ä¿ç•™CSVæ ¼å¼ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
        if format_type.lower() == 'excel':
            csv_filepath = filepath.replace('.txt', '_analysis.csv')
            analyzer.export_report(csv_filepath, 'csv')
            logger.info("ğŸ“ åŒæ™‚åŒ¯å‡ºCSVæ ¼å¼: %s", csv_filepath)
        
    except Exception as e:
        logger.error("âŒ éŒ¯èª¤: %s", e)
        sys.exit(1)


if __name__ == "__main__":
    main()
