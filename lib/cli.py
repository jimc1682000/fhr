"""CLI orchestrator extracted from attendance_analyzer.main().

Keeps behavior-compatible semantics: normal runs do not call sys.exit,
error paths may call sys.exit(1) to match prior tests.
"""
import argparse
import logging
import os
import sys
from datetime import datetime


def run(argv: list | None = None) -> None:
    from attendance_analyzer import AttendanceAnalyzer, logger  # reuse same logger
    from lib.filename import parse_range_and_user
    from lib.state import AttendanceStateManager

    parser = argparse.ArgumentParser(
        description='è€ƒå‹¤åˆ†æç³»çµ± - æ”¯æ´å¢é‡åˆ†æé¿å…é‡è¤‡è™•ç†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:
  # é è¨­å¢é‡åˆ†æï¼ˆæ¨è–¦ï¼‰
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt

  # å¼·åˆ¶å®Œæ•´é‡æ–°åˆ†æ
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt --full

  # æ¸…é™¤ä½¿ç”¨è€…ç‹€æ…‹å¾Œé‡æ–°åˆ†æ
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt --reset-state

  # æŒ‡å®šè¼¸å‡ºæ ¼å¼
  python attendance_analyzer.py 202508-å“¡å·¥å§“å-å‡ºå‹¤è³‡æ–™.txt csv
        """
    )

    parser.add_argument('filepath', help='è€ƒå‹¤æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('format', nargs='?', default='excel',
                        choices=['excel', 'csv'], help='è¼¸å‡ºæ ¼å¼ (é è¨­: excel)')
    parser.add_argument('--incremental', '-i', action='store_true', default=True,
                        help='å•Ÿç”¨å¢é‡åˆ†ææ¨¡å¼ (é è¨­é–‹å•Ÿ)')
    parser.add_argument('--full', '-f', action='store_true',
                        help='å¼·åˆ¶å®Œæ•´é‡æ–°åˆ†æ')
    parser.add_argument('--reset-state', '-r', action='store_true',
                        help='æ¸…é™¤æŒ‡å®šä½¿ç”¨è€…çš„ç‹€æ…‹è¨˜éŒ„')
    parser.add_argument('--debug', action='store_true',
                        help='å•Ÿç”¨ debug æ¨¡å¼ï¼ˆè©³ç´°æ—¥èªŒã€ä¸å¯«å…¥ç‹€æ…‹æª”ï¼‰')
    parser.add_argument(
        '--export-policy',
        choices=['merge', 'archive'],
        default='merge',
        help='åŒ¯å‡ºç­–ç•¥ï¼šmerge ç›´æ¥è¦†å¯«ä¸»æª”æ¡ˆï¼Œarchive ä¿ç•™ timestamp å‚™ä»½ã€‚',
    )
    parser.add_argument(
        '--cleanup-exports',
        action='store_true',
        help='æ¸…é™¤ timestamp å‚™ä»½ï¼›æ­é… --debug æ™‚åŒæ™‚åˆªé™¤æœ¬æ¬¡ç”¢å‡ºçš„åŒ¯å‡ºæª”æ¡ˆã€‚',
    )

    args = parser.parse_args(argv[1:] if argv is not None else None)

    filepath = args.filepath
    format_type = args.format
    incremental_mode = args.incremental and not args.full
    export_policy = args.export_policy
    cleanup_exports = args.cleanup_exports

    if args.debug:
        logger.setLevel(logging.DEBUG)
        logger.debug("ğŸ CLI Debug æ¨¡å¼å•Ÿå‹•ï¼šå°‡ç•¥éç‹€æ…‹å¯«å…¥ä¸¦è¼¸å‡ºè©³ç´°è¨Šæ¯ã€‚")

    if args.reset_state:
        # analyzer_temp = AttendanceAnalyzer()  # Variable assigned but never used
        user_name, _, _ = parse_range_and_user(filepath)
        if user_name:
            state_manager = AttendanceStateManager(read_only=args.debug)
            if args.debug:
                logger.debug("ğŸ›¡ï¸  Debug æ¨¡å¼ï¼šç•¥éæ¸…é™¤ä½¿ç”¨è€… %s çš„ç‹€æ…‹", user_name)
            elif user_name in state_manager.state_data.get("users", {}):
                del state_manager.state_data["users"][user_name]
                state_manager.save_state()
                logger.info(
                    "ğŸ—‘ï¸  ç‹€æ…‹æª” 'attendance_state.json' å·²æ¸…é™¤ä½¿ç”¨è€… %s çš„è¨˜éŒ„ @ %s",
                    user_name,
                    datetime.now().isoformat(),
                )
            else:
                logger.info("â„¹ï¸  ä½¿ç”¨è€… %s æ²’æœ‰ç¾æœ‰ç‹€æ…‹éœ€è¦æ¸…é™¤", user_name)
        else:
            logger.warning("âš ï¸  ç„¡æ³•å¾æª”åè­˜åˆ¥ä½¿ç”¨è€…ï¼Œç„¡æ³•åŸ·è¡Œç‹€æ…‹é‡è¨­")
            sys.exit(1)

    try:
        analyzer = AttendanceAnalyzer(debug=args.debug)

        if incremental_mode:
            logger.info("ğŸ“‚ æ­£åœ¨è§£æè€ƒå‹¤æª”æ¡ˆ... (å¢é‡åˆ†ææ¨¡å¼)")
        else:
            logger.info("ğŸ“‚ æ­£åœ¨è§£æè€ƒå‹¤æª”æ¡ˆ... (å®Œæ•´åˆ†ææ¨¡å¼)")

        analyzer.parse_attendance_file(filepath, incremental=incremental_mode)

        logger.info("ğŸ“ æ­£åœ¨åˆ†çµ„è¨˜éŒ„...")
        analyzer.group_records_by_day()

        logger.info("ğŸ” æ­£åœ¨åˆ†æè€ƒå‹¤...")
        analyzer.analyze_attendance()

        logger.info("ğŸ“Š æ­£åœ¨ç”Ÿæˆå ±å‘Š...")
        report = analyzer.generate_report()

        logger.info("\n")
        for line in report.split('\n'):
            logger.info(line)

        exported_files: list[str] = []
        backup_files: list[str] = []

        if format_type.lower() == 'csv':
            output_filepath = filepath.replace('.txt', '_analysis.csv')
            backup_path = analyzer.export_report(
                output_filepath, 'csv', export_policy=export_policy
            )
            exported_files.append(output_filepath)
            if backup_path:
                backup_files.append(backup_path)
            logger.info("âœ… CSVå ±å‘Šå·²åŒ¯å‡º: %s", output_filepath)
        else:
            output_filepath = filepath.replace('.txt', '_analysis.xlsx')
            backup_path = analyzer.export_report(
                output_filepath, 'excel', export_policy=export_policy
            )
            exported_files.append(output_filepath)
            if backup_path:
                backup_files.append(backup_path)
            logger.info("âœ… Excelå ±å‘Šå·²åŒ¯å‡º: %s", output_filepath)

        if format_type.lower() == 'excel':
            csv_filepath = filepath.replace('.txt', '_analysis.csv')
            backup_path = analyzer.export_report(
                csv_filepath, 'csv', export_policy=export_policy
            )
            exported_files.append(csv_filepath)
            if backup_path:
                backup_files.append(backup_path)
            logger.info("ğŸ“ åŒæ™‚åŒ¯å‡ºCSVæ ¼å¼: %s", csv_filepath)

        if cleanup_exports:
            from lib.export_cleanup import (
                cleanup_exports as cleanup_exports_helper,
                list_backups,
            )

            timestamp_candidates: set[str] = set()
            for path in exported_files:
                for candidate in list_backups(path):
                    timestamp_candidates.add(os.path.abspath(candidate))
            for backup in backup_files:
                if os.path.exists(backup):
                    timestamp_candidates.add(os.path.abspath(backup))

            canonical_candidates: set[str] = set()
            if args.debug:
                for path in exported_files:
                    if os.path.exists(path):
                        canonical_candidates.add(os.path.abspath(path))

            if not timestamp_candidates and not canonical_candidates:
                logger.info("â„¹ï¸ æ²’æœ‰å¯æ¸…é™¤çš„åŒ¯å‡ºæª”æ¡ˆ")
            else:
                logger.info("ğŸ§¹ å¯æ¸…é™¤åŒ¯å‡ºæª”æ¡ˆï¼š")
                for candidate in sorted(timestamp_candidates):
                    logger.info("   - %s", os.path.basename(candidate))
                for candidate in sorted(canonical_candidates):
                    logger.info("   - %s (æœ¬æ¬¡è¼¸å‡º)", os.path.basename(candidate))

                response = input("æ˜¯å¦åˆªé™¤ä¸Šè¿°æª”æ¡ˆï¼Ÿ[y/N]: ").strip().lower()
                if response not in {"y", "yes"}:
                    logger.info("â„¹ï¸ å·²å–æ¶ˆåŒ¯å‡ºæ¸…ç†")
                else:
                    removed_paths: set[str] = set()
                    for path in exported_files:
                        removed = cleanup_exports_helper(
                            path, include_canonical=args.debug
                        )
                        removed_paths.update(os.path.abspath(p) for p in removed)
                    for backup in backup_files:
                        if os.path.exists(backup):
                            os.remove(backup)
                            removed_paths.add(os.path.abspath(backup))
                    if removed_paths:
                        removed_display = ', '.join(
                            sorted(os.path.basename(p) for p in removed_paths)
                        )
                        if args.debug:
                            logger.info("ğŸ§¹ Debug åŒ¯å‡ºæª”æ¡ˆå·²æ¸…é™¤: %s", removed_display)
                        else:
                            logger.info("ğŸ§¹ å·²ç§»é™¤ timestamp å‚™ä»½: %s", removed_display)
                    else:
                        logger.info("â„¹ï¸ æ²’æœ‰æª”æ¡ˆè¢«åˆªé™¤")

    except Exception as e:
        logger.error("âŒ éŒ¯èª¤: %s", e)
        sys.exit(1)
